{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02bc2d5-ed73-4272-8431-46957e402b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "def pad_image_to_divisible(image, p):\n",
    "    # 获取图片的高度和宽度\n",
    "    _, _, h, w = image.shape\n",
    "    \n",
    "    # 计算需要的 padding 大小\n",
    "    pad_h = (p - h % p) % p\n",
    "    pad_w = (p - w % p) % p\n",
    "    \n",
    "    # 对图片进行 padding，使用 `torch.nn.functional.pad`\n",
    "    # `pad` 参数的格式是 (pad_left, pad_right, pad_top, pad_bottom)\n",
    "    padding = (0, pad_w, 0, pad_h)\n",
    "    padded_image = F.pad(image, padding, mode='constant', value=0)\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(num_features, num_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_features)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(F.gelu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenMixer(nn.Module):\n",
    "    def __init__(self, num_patches, embedding_dim, patch_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp = MLP(num_patches, patch_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x = self.mlp(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChannelMixer(nn.Module):\n",
    "    def __init__(self, embedding_dim, filter_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp = MLP(embedding_dim, filter_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = self.mlp(x)\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MixerLayer(nn.Module):\n",
    "    def __init__(self, num_patches, embedding_dim, patch_dim, filter_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.token_mixer = TokenMixer(\n",
    "            num_patches, embedding_dim, patch_dim, dropout\n",
    "        )\n",
    "        self.channel_mixer = ChannelMixer(\n",
    "            embedding_dim, filter_dim, dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.token_mixer(x)\n",
    "        x = self.channel_mixer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Vision_MIXER(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        patch_size,\n",
    "        number_class,\n",
    "        embedding_dim = 512,\n",
    "        patch_dim = 256,\n",
    "        filter_dim = 2048,\n",
    "        layer_nr = 10,\n",
    "        dropout = 0.1\n",
    "    ):\n",
    "        super(Vision_MIXER,self).__init__()\n",
    "        batch,_,window_length,sensor_channel_nr = input_shape\n",
    "        temp_x = torch.randn(1, 1, window_length, sensor_channel_nr)\n",
    "        y = pad_image_to_divisible(temp_x,patch_size)\n",
    "        padded_window_length = y.shape[2]\n",
    "        padded_sensor_channel = y.shape[3]\n",
    "        self.num_patches = int(padded_window_length/patch_size)*int(padded_sensor_channel/patch_size)\n",
    "        self.padded_window_length     = padded_window_length\n",
    "        self.padded_sensor_channel    = padded_sensor_channel\n",
    "        self.patch_size               = patch_size\n",
    "        self.number_class             = number_class\n",
    "        self.embedding_dim            = embedding_dim\n",
    "        self.patch_dim                = patch_dim\n",
    "        self.filter_dim               = filter_dim\n",
    "        self.layer_nr                 = layer_nr\n",
    "\n",
    "        self.patcher = nn.Conv2d(\n",
    "            1, self.embedding_dim, kernel_size=self.patch_size, stride=self.patch_size\n",
    "        )\n",
    "\n",
    "        self.mixers = nn.Sequential(\n",
    "            *[\n",
    "                MixerLayer(self.num_patches, self.embedding_dim, self.patch_dim, self.filter_dim , dropout)\n",
    "                for _ in range(self.layer_nr)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(embedding_dim, number_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = pad_image_to_divisible(x,self.patch_size)\n",
    "        x = self.patcher(x)\n",
    "        batch_size, num_features, _, _ = x.shape\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.view(batch_size, -1, num_features)\n",
    "\n",
    "        x = self.mixers(x)\n",
    "        # embedding.shape == (batch_size, num_patches, num_features)\n",
    "        x = x.mean(dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33873f6a-b331-4c89-ad58-2e65a912a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 128\n",
    "sensor_channel = 9\n",
    "input_shape=(1,1,window_length,sensor_channel)\n",
    "patch_size=3\n",
    "number_class=10\n",
    "embedding_dim=512\n",
    "patch_dim=256\n",
    "filter_dim=2048\n",
    "layer_nr=10\n",
    "\n",
    "model = Vision_MIXER( input_shape,        patch_size,        number_class)\n",
    "\n",
    "x = torch.randn(input_shape)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584e285-adf1-4ccb-b708-e5978f094bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6699af7-b04f-4cc7-883f-e64115b65954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, expansion_factor, dropout):\n",
    "        super().__init__()\n",
    "        num_hidden = num_features * expansion_factor\n",
    "        self.fc1 = nn.Linear(num_features, num_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_features)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(F.gelu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TokenMixer(nn.Module):\n",
    "    def __init__(self, num_features, num_patches, expansion_factor, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(num_features)\n",
    "        self.mlp = MLP(num_patches, expansion_factor, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        # x.shape == (batch_size, num_features, num_patches)\n",
    "        x = self.mlp(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChannelMixer(nn.Module):\n",
    "    def __init__(self, num_features, num_patches, expansion_factor, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(num_features)\n",
    "        self.mlp = MLP(num_features, expansion_factor, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = self.mlp(x)\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class MixerLayer(nn.Module):\n",
    "    def __init__(self, num_features, num_patches, expansion_factor, dropout):\n",
    "        super().__init__()\n",
    "        self.token_mixer = TokenMixer(\n",
    "            num_patches, num_features, expansion_factor, dropout\n",
    "        )\n",
    "        self.channel_mixer = ChannelMixer(\n",
    "            num_patches, num_features, expansion_factor, dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        x = self.token_mixer(x)\n",
    "        x = self.channel_mixer(x)\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        return x\n",
    "\n",
    "\n",
    "def check_sizes(image_size, patch_size):\n",
    "    sqrt_num_patches, remainder = divmod(image_size, patch_size)\n",
    "    assert remainder == 0, \"`image_size` must be divisibe by `patch_size`\"\n",
    "    num_patches = sqrt_num_patches ** 2\n",
    "    return num_patches\n",
    "\n",
    "\n",
    "class MLPMixer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=256,\n",
    "        patch_size=16,\n",
    "        in_channels=3,\n",
    "        num_features=128,\n",
    "        expansion_factor=2,\n",
    "        num_layers=8,\n",
    "        num_classes=10,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        num_patches = check_sizes(image_size, patch_size)\n",
    "        super().__init__()\n",
    "        # per-patch fully-connected is equivalent to strided conv2d\n",
    "        self.patcher = nn.Conv2d(\n",
    "            in_channels, num_features, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "        self.mixers = nn.Sequential(\n",
    "            *[\n",
    "                MixerLayer(num_patches, num_features, expansion_factor, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patcher(x)\n",
    "        batch_size, num_features, _, _ = patches.shape\n",
    "        patches = patches.permute(0, 2, 3, 1)\n",
    "        patches = patches.view(batch_size, -1, num_features)\n",
    "        # patches.shape == (batch_size, num_patches, num_features)\n",
    "        embedding = self.mixers(patches)\n",
    "        # embedding.shape == (batch_size, num_patches, num_features)\n",
    "        embedding = embedding.mean(dim=1)\n",
    "        logits = self.classifier(embedding)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46d2dc5-aac5-445e-95dd-35512fb3d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# 创建一个 3x3 的 tensor，元素服从标准正态分布\n",
    "x = torch.randn(1,1,224,224)\n",
    "\n",
    "num_features = 32\n",
    "patch_size = 16\n",
    "patcher = nn.Conv2d(\n",
    "            1, num_features, kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "\n",
    "y = patcher(x)\n",
    "\n",
    "batch_size, num_features, _, _ = y.shape\n",
    "patches = y.permute(0, 2, 3, 1)\n",
    "patches = patches.view(batch_size, -1, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7968dc79-6c3f-4b43-be6a-5e825bdaa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_divisible(image, p):\n",
    "    # 获取图片的高度和宽度\n",
    "    _, _, h, w = image.shape\n",
    "    \n",
    "    # 计算需要的 padding 大小\n",
    "    pad_h = (p - h % p) % p\n",
    "    pad_w = (p - w % p) % p\n",
    "    \n",
    "    # 对图片进行 padding，使用 `torch.nn.functional.pad`\n",
    "    # `pad` 参数的格式是 (pad_left, pad_right, pad_top, pad_bottom)\n",
    "    padding = (0, pad_w, 0, pad_h)\n",
    "    padded_image = F.pad(image, padding, mode='constant', value=0)\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "# 示例图片张量，形状为 (batch_size, channels, height, width)\n",
    "image = torch.randn(1, 1, 8, 5)\n",
    "\n",
    "# patch 的大小\n",
    "p = 4\n",
    "\n",
    "y = pad_image_to_divisible(image,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd30243-c989-4121-90ad-df8f9cf11fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_divisible(image, p):\n",
    "    # 获取图片的高度和宽度\n",
    "    _, _, h, w = image.shape\n",
    "    \n",
    "    # 计算需要的 padding 大小\n",
    "    pad_h = (p - h % p) % p\n",
    "    pad_w = (p - w % p) % p\n",
    "    \n",
    "    # 对图片进行 padding，使用 `torch.nn.functional.pad`\n",
    "    # `pad` 参数的格式是 (pad_left, pad_right, pad_top, pad_bottom)\n",
    "    padding = (0, pad_w, 0, pad_h)\n",
    "    padded_image = F.pad(image, padding, mode='constant', value=0)\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(num_features, num_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_features)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(F.gelu(self.fc1(x)))\n",
    "        x = self.dropout2(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenMixer(nn.Module):\n",
    "    def __init__(self, num_patches, embedding_dim, patch_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp = MLP(num_patches, patch_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x = self.mlp(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChannelMixer(nn.Module):\n",
    "    def __init__(self, embedding_dim, filter_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp = MLP(embedding_dim, filter_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        residual = x\n",
    "        x = self.norm(x)\n",
    "        x = self.mlp(x)\n",
    "        # x.shape == (batch_size, num_patches, num_features)\n",
    "        out = x + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MixerLayer(nn.Module):\n",
    "    def __init__(self, num_patches, embedding_dim, patch_dim, filter_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.token_mixer = TokenMixer(\n",
    "            num_patches, embedding_dim, patch_dim, dropout\n",
    "        )\n",
    "        self.channel_mixer = ChannelMixer(\n",
    "            embedding_dim, filter_dim, dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.token_mixer(x)\n",
    "        x = self.channel_mixer(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Vision_MIXER(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        patch_size,\n",
    "        number_class,\n",
    "        embedding_dim,\n",
    "        patch_dim,\n",
    "        filter_dim,\n",
    "        layer_nr,\n",
    "        dropout = 0.1\n",
    "    ):\n",
    "        super(Vision_MIXER,self).__init__()\n",
    "        batch,_,window_length,sensor_channel_nr = input_shape\n",
    "        temp_x = torch.randn(1, 1, window_length, sensor_channel_nr)\n",
    "        y = pad_image_to_divisible(temp_x,patch_size)\n",
    "        padded_window_length = y.shape[2]\n",
    "        padded_sensor_channel = y.shape[3]\n",
    "        self.num_patches = int(padded_window_length/patch_size)*int(padded_sensor_channel/patch_size)\n",
    "        self.padded_window_length     = padded_window_length\n",
    "        self.padded_sensor_channel    = padded_sensor_channel\n",
    "        self.patch_size               = patch_size\n",
    "        self.number_class             = number_class\n",
    "        self.embedding_dim            = embedding_dim\n",
    "        self.patch_dim                = patch_dim\n",
    "        self.filter_dim               = filter_dim\n",
    "        self.layer_nr                 = layer_nr\n",
    "\n",
    "        self.patcher = nn.Conv2d(\n",
    "            1, self.embedding_dim, kernel_size=self.patch_size, stride=self.patch_size\n",
    "        )\n",
    "\n",
    "        self.mixers = nn.Sequential(\n",
    "            *[\n",
    "                MixerLayer(self.num_patches, self.embedding_dim, self.patch_dim, self.filter_dim , dropout)\n",
    "                for _ in range(self.layer_nr)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(embedding_dim, number_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = pad_image_to_divisible(x,self.patch_size)\n",
    "        x = self.patcher(x)\n",
    "        batch_size, num_features, _, _ = x.shape\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.view(batch_size, -1, num_features)\n",
    "\n",
    "        x = self.mixers(x)\n",
    "        # embedding.shape == (batch_size, num_patches, num_features)\n",
    "        x = x.mean(dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1709ac-a63e-45a1-860c-6d1b1e19d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 128\n",
    "sensor_channel = 9\n",
    "input_shape=(1,1,window_length,sensor_channel)\n",
    "patch_size=3\n",
    "number_class=10\n",
    "embedding_dim=512\n",
    "patch_dim=256\n",
    "filter_dim=2048\n",
    "layer_nr=10\n",
    "\n",
    "model = Vision_MIXER( input_shape,        patch_size,        number_class,        embedding_dim,        patch_dim,        filter_dim,        layer_nr)\n",
    "\n",
    "x = torch.randn(input_shape)\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dda32970-acc8-4e82-b3a2-5084601e8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1963ef62-ef13-49db-b394-5155c188ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "macs, params = get_model_complexity_info(model, \n",
    "                                         (1, window_length, sensor_channel), \n",
    "                                         as_strings=True, print_per_layer_stat=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d799ac-ae98-48d2-8b09-ad1d88022199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.69 M'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3425f995-f0c8-40e3-99bb-63ce87da1e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.05 GMac'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88b3ad6f-94a6-4d1f-a235-2724ef80abcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.222222222222221"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3330111-57cb-4072-aeb8-f46cb7024176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc23",
   "language": "python",
   "name": "iswc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
