{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed5bf9f1-3b90-4a7d-b7fe-fb4129a07cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "#from utils.utils import *\n",
    "import os\n",
    "from torch.nn.utils import weight_norm\n",
    "from contiguous_params import ContiguousParams\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        pe = pe.transpose(1,2)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],requires_grad=False)\n",
    "        # x = x + Variable(self.pe, requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads = 8, drop_rate = 0):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.k, self.heads = k, heads\n",
    "        # map k-dimentional input to k*heads dimentions\n",
    "        self.tokeys    = nn.Linear(k, k * heads, bias = False)\n",
    "        self.toqueries = nn.Linear(k, k * heads, bias = False)\n",
    "        self.tovalues  = nn.Linear(k, k * heads, bias = False)\n",
    "        # set dropout rate\n",
    "        self.dropout_attention = nn.Dropout(drop_rate)\n",
    "        # squeeze to k dimentions through linear transformation\n",
    "        self.unifyheads = nn.Linear(heads * k, k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "        queries = self.toqueries(x).view(b, t, h, k)\n",
    "        keys    = self.tokeys(x).view(b, t, h, k)\n",
    "        values  = self.tovalues(x).view(b, t, h, k)\n",
    "        # squeeze head into batch dimension\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "        keys    = keys.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "        values  = values.transpose(1, 2).contiguous().view(b * h, t, k)\n",
    "        # normalize the dot products\n",
    "        queries = queries / (k ** (1/4))\n",
    "        keys = keys / (k ** (1/4))\n",
    "        # matrix multiplication\n",
    "        dot  = torch.bmm(queries, keys.transpose(1,2))\n",
    "        # softmax normalization\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        dot = self.dropout_attention(dot)\n",
    "        out = torch.bmm(dot, values).view(b, h, t, k)\n",
    "        # swap h, t back, unify heads\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, h*k)\n",
    "        \n",
    "        return self.unifyheads(out) # (b, t, k)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, k, heads, drop_rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.attention = SelfAttention(k, heads = heads, drop_rate = drop_rate)\n",
    "        self.norm1 = nn.LayerNorm(k)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(k, 4*k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*k, k)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(k)\n",
    "        self.dropout_forward = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # perform self-attention\n",
    "        attended = self.attention(x)\n",
    "        # perform layer norm\n",
    "        x = self.norm1(attended + x)\n",
    "        # feedforward and layer norm\n",
    "        feedforward = self.mlp(x)\n",
    "        \n",
    "        return self.dropout_forward(self.norm2(feedforward + x))\n",
    "\n",
    "class Chomp2d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp2d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class IMU_Fusion_Block(nn.Module):\n",
    "    def __init__(self, input_2Dfeature_channel, input_channel, \n",
    "                 feature_channel, kernel_size_grav,\n",
    "                 scale_num, dataset_name):\n",
    "        super(IMU_Fusion_Block, self).__init__()\n",
    "        \n",
    "        self.scale_num         = scale_num\n",
    "        self.input_channel     = input_channel\n",
    "        self.tcn_grav_convs    = []\n",
    "        self.tcn_gyro_convs    = []\n",
    "        self.tcn_acc_convs     = []\n",
    "        \n",
    "        for i in range(self.scale_num):\n",
    "            \n",
    "            dilation_num_grav = i+1\n",
    "            \n",
    "            padding_grav      = (kernel_size_grav - 1) * dilation_num_grav\n",
    "            kernel_size_gyro  = padding_grav\n",
    "            kernel_size_acc   = padding_grav + 1\n",
    "            \n",
    "            tcn_grav = nn.Sequential(\n",
    "                weight_norm(nn.Conv2d(input_2Dfeature_channel, feature_channel, \n",
    "                                      (1,kernel_size_grav), 1, (0,padding_grav), \n",
    "                                      dilation=dilation_num_grav)),\n",
    "                Chomp2d(padding_grav),\n",
    "                nn.ReLU(),\n",
    "                )\n",
    "            \n",
    "            \n",
    "            if kernel_size_gyro == 1:\n",
    "                tcn_gyro = nn.Sequential(\n",
    "                    weight_norm(nn.Conv2d(input_2Dfeature_channel, feature_channel, \n",
    "                                          (1,1), 1, (0,0), \n",
    "                                          dilation=1)),\n",
    "                    nn.ReLU(),\n",
    "                    )\n",
    "            else:\n",
    "                tcn_gyro = nn.Sequential(\n",
    "                    weight_norm(nn.Conv2d(input_2Dfeature_channel, feature_channel, \n",
    "                                          (1,kernel_size_gyro), 1, (0,(kernel_size_gyro-1)*1), \n",
    "                                          dilation=1)),\n",
    "                    Chomp2d((kernel_size_gyro-1)*1),\n",
    "                    nn.ReLU(),\n",
    "                    )\n",
    "            \n",
    "            tcn_acc = nn.Sequential(\n",
    "                weight_norm(nn.Conv2d(input_2Dfeature_channel, feature_channel, \n",
    "                                      (1,kernel_size_acc), 1, (0,(kernel_size_acc-1)*1), \n",
    "                                      dilation=1)),\n",
    "                Chomp2d((kernel_size_acc-1)*1),\n",
    "                nn.ReLU(),\n",
    "                )\n",
    "            \n",
    "            setattr(self, 'tcn_grav_convs%i' % i, tcn_grav)\n",
    "            self.tcn_grav_convs.append(tcn_grav)\n",
    "            setattr(self, 'tcn_gyro_convs%i' % i, tcn_gyro)\n",
    "            self.tcn_gyro_convs.append(tcn_gyro)\n",
    "            setattr(self, 'tcn_acc_convs%i' % i, tcn_acc)\n",
    "            self.tcn_acc_convs.append(tcn_acc)\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "                nn.Linear(3*feature_channel, 1),\n",
    "                # nn.Tanh()\n",
    "                nn.PReLU()\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_grav = x[:,:,0:3,:]\n",
    "        x_gyro = x[:,:,3:6,:]\n",
    "        x_acc  = x[:,:,6:9,:]\n",
    "    \n",
    "        for i in range(self.scale_num):\n",
    "            \n",
    "            out_grav = self.tcn_grav_convs[i](x_grav).unsqueeze(4)\n",
    "            out_gyro = self.tcn_gyro_convs[i](x_gyro).unsqueeze(4)\n",
    "            out_acc  = self.tcn_acc_convs[i](x_acc)\n",
    "            \n",
    "            if i == 0:\n",
    "                out_attitude = torch.cat([out_grav, out_gyro], dim=4)\n",
    "                out_dynamic  = out_acc\n",
    "            else:\n",
    "                out_attitude = torch.cat([out_attitude, out_grav], dim=4)\n",
    "                out_attitude = torch.cat([out_attitude, out_gyro], dim=4)\n",
    "                out_dynamic  = torch.cat([out_dynamic, out_acc], dim=2)\n",
    "                \n",
    "        # (batch_size, time_length, sensor_num*scale_num, 3(xyz), feature_chnnl)\n",
    "        out_attitude = out_attitude.permute(0,3,4,2,1)\n",
    "        # (batch_size, time_length, sensor_num*scale_num, 3(xyz)*feature_chnnl)\n",
    "        out_attitude = out_attitude.reshape(out_attitude.shape[0], out_attitude.shape[1], out_attitude.shape[2], -1)\n",
    "        # time-step-wise sensor attention, sensor_attn:(batch_size, time_length, sensor_num*scale_num, 1)\n",
    "        sensor_attn  = self.attention(out_attitude).squeeze(3)\n",
    "        sensor_attn  = F.softmax(sensor_attn, dim=2).unsqueeze(-1)\n",
    "        out_attitude = sensor_attn * out_attitude\n",
    "        \n",
    "        # used for normalization\n",
    "        norm_num     = torch.mean(sensor_attn.squeeze(-1), dim=1)\n",
    "        norm_num     = torch.pow(norm_num, 2)\n",
    "        norm_num     = torch.sqrt(torch.sum(norm_num, dim=1))\n",
    "        norm_num     = (pow(self.scale_num,0.5)/norm_num).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        \n",
    "        out_attitude = out_attitude * norm_num\n",
    "        \n",
    "        # (batch_size, time_length, sensor_num*scale_num, 3(xyz), feature_chnnl)\n",
    "        out_attitude = out_attitude.reshape(out_attitude.shape[0], out_attitude.shape[1], out_attitude.shape[2], 3, -1)\n",
    "        # (batch_size, time_length, sensor_num*scale_num*3(xyz), feature_chnnl)\n",
    "        out_attitude = out_attitude.reshape(out_attitude.shape[0], out_attitude.shape[1], out_attitude.shape[2]*3, -1)\n",
    "        # (batch_size, feature_chnnl, sensor_num*scale_num*3(xyz), time_length)\n",
    "        out_attitude = out_attitude.permute(0,3,2,1)\n",
    "        \n",
    "        # concatenate all the different scales\n",
    "        out_attitude = torch.split(out_attitude, 6, dim=2)\n",
    "        for j in range(len(out_attitude)):\n",
    "            per_scale_attitude = torch.split(out_attitude[j], 3, dim=2)\n",
    "            for k in range(len(per_scale_attitude)):\n",
    "                if k == 0:\n",
    "                    per_attitude   = per_scale_attitude[k]\n",
    "                else:\n",
    "                    per_attitude   = per_attitude + per_scale_attitude[k]\n",
    "            if j == 0:\n",
    "                all_attitude = per_attitude\n",
    "            else:\n",
    "                all_attitude = torch.cat([all_attitude, per_attitude], dim=2)\n",
    "        out_attitude = all_attitude\n",
    "        \n",
    "        out          = torch.cat([out_attitude, out_dynamic], dim = 2)\n",
    "        \n",
    "        return out, sensor_attn\n",
    "\n",
    "class If_ConvTransformer(nn.Module):\n",
    "    def __init__(self, input_2Dfeature_channel, input_channel, feature_channel,\n",
    "                 kernel_size, kernel_size_grav, scale_num, feature_channel_out,\n",
    "                 multiheads, drop_rate, dataset_name, data_length, num_class):\n",
    "        \n",
    "        super(If_ConvTransformer, self).__init__()\n",
    "        \n",
    "        self.IMU_fusion_block = IMU_Fusion_Block(input_2Dfeature_channel, input_channel, feature_channel,\n",
    "                                                 kernel_size_grav, scale_num, dataset_name)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(feature_channel, feature_channel, (1,kernel_size), 1, (0,kernel_size//2)),\n",
    "            nn.BatchNorm2d(feature_channel),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(feature_channel, feature_channel, (1,kernel_size), 1, (0,kernel_size//2)),\n",
    "            nn.BatchNorm2d(feature_channel),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(feature_channel, feature_channel, (1,kernel_size), 1, (0,kernel_size//2)),\n",
    "            nn.BatchNorm2d(feature_channel),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2)\n",
    "            )\n",
    "        \n",
    "        if input_channel  == 12:\n",
    "            reduced_channel = 6\n",
    "        else:\n",
    "            reduced_channel = 3\n",
    "        \n",
    "        self.transition = nn.Sequential(\n",
    "            nn.Conv1d(feature_channel*(input_channel-reduced_channel)*scale_num, feature_channel_out, 1, 1),\n",
    "            nn.BatchNorm1d(feature_channel_out),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.position_encode = PositionalEncoding(feature_channel_out, drop_rate, data_length)\n",
    "        \n",
    "        self.transformer_block1 = TransformerBlock(feature_channel_out, multiheads, drop_rate)\n",
    "        \n",
    "        self.transformer_block2 = TransformerBlock(feature_channel_out, multiheads, drop_rate)\n",
    "        \n",
    "        self.global_ave_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.linear = nn.Linear(feature_channel_out, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # hidden = None\n",
    "        batch_size = x.shape[0]\n",
    "        feature_channel = x.shape[1]\n",
    "        input_channel = x.shape[2]\n",
    "        data_length = x.shape[-1]\n",
    "        \n",
    "        x, out_attn = self.IMU_fusion_block(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(batch_size, -1, data_length)\n",
    "        print(x.shape)\n",
    "        x = self.transition(x)\n",
    "        \n",
    "        x = self.position_encode(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        x = self.transformer_block1(x)\n",
    "        x = self.transformer_block2(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        x = self.global_ave_pooling(x).squeeze()\n",
    "        \n",
    "        output = self.linear(x)\n",
    "        \n",
    "        return output, out_attn\n",
    "    \n",
    "def train_op(network, EPOCH, BATCH_SIZE, LR,\n",
    "             train_x, train_y, val_x, val_y, X_test, y_test,\n",
    "             output_directory_models, log_training_duration, test_split):\n",
    "    # prepare training_data\n",
    "    if train_x.shape[0] % BATCH_SIZE == 1:\n",
    "        drop_last_flag = True\n",
    "    else:\n",
    "        drop_last_flag = False\n",
    "    torch_dataset = Data.TensorDataset(torch.FloatTensor(train_x), torch.tensor(train_y).long())\n",
    "    train_loader = Data.DataLoader(dataset = torch_dataset,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    shuffle = True,\n",
    "                                    drop_last = drop_last_flag\n",
    "                                   )\n",
    "    \n",
    "    # init lr&train&test loss&acc log\n",
    "    lr_results = []\n",
    "    \n",
    "    loss_train_results = []\n",
    "    accuracy_train_results = []\n",
    "    \n",
    "    loss_validation_results = []\n",
    "    accuracy_validation_results = []\n",
    "    macro_f1_val_results        = []\n",
    "    \n",
    "    loss_test_results = []\n",
    "    accuracy_test_results = []\n",
    "    macro_f1_test_results       = []\n",
    "    \n",
    "    # prepare optimizer&scheduler&loss_function\n",
    "    parameters = ContiguousParams(network.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters.contiguous(),lr = LR)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, \n",
    "                                                           patience=5,\n",
    "                                                           min_lr=LR/10, verbose=True)\n",
    "    # loss_function = nn.CrossEntropyLoss(reduction='sum')\n",
    "    loss_function = LabelSmoothingCrossEntropy()\n",
    "    \n",
    "    # save init model    \n",
    "    output_directory_init = output_directory_models+'init_model.pkl'\n",
    "    torch.save(network.state_dict(), output_directory_init)   # only save the init parameters\n",
    "    \n",
    "    training_duration_logs = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range (EPOCH):\n",
    "        \n",
    "        epoch_tau = epoch+1\n",
    "        tau = max(1 - (epoch_tau - 1) / 50, 0.5)\n",
    "        for m in network.modules():\n",
    "            if hasattr(m, '_update_tau'):\n",
    "                m._update_tau(tau)\n",
    "                # print(a)\n",
    "        \n",
    "        for step, (x,y) in enumerate(train_loader):\n",
    "            \n",
    "            batch_x = x.cuda()\n",
    "            batch_y = y.cuda()\n",
    "            output_bc = network(batch_x)[0]\n",
    "            \n",
    "            # cal the sum of pre loss per batch \n",
    "            loss = loss_function(output_bc, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # test per epoch\n",
    "        network.eval()\n",
    "        test_flag = True\n",
    "        # loss_train:loss of training set; accuracy_train:pre acc of training set\n",
    "        loss_train, accuracy_train, _ = get_test_loss_acc(network, loss_function, train_x, train_y, test_split)\n",
    "        loss_validation, accuracy_validation, macro_f1_val = get_test_loss_acc(network, loss_function, val_x, val_y, test_split)\n",
    "        loss_test, accuracy_test, macro_f1_test = get_test_loss_acc(network, loss_function, X_test, y_test, test_split)\n",
    "        test_flag = False\n",
    "        network.train()\n",
    "        \n",
    "        # update lr\n",
    "        scheduler.step(accuracy_validation)\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        ######################################dropout#####################################\n",
    "        # loss_train, accuracy_train = get_loss_acc(network.eval(), loss_function, train_x, train_y, test_split)\n",
    "        \n",
    "        # loss_validation, accuracy_validation = get_loss_acc(network.eval(), loss_function, test_x, test_y, test_split)\n",
    "        \n",
    "        # network.train()\n",
    "        ##################################################################################\n",
    "        \n",
    "        # log lr&train&validation loss&acc per epoch\n",
    "        lr_results.append(lr)\n",
    "        loss_train_results.append(loss_train)    \n",
    "        accuracy_train_results.append(accuracy_train)\n",
    "        \n",
    "        loss_validation_results.append(loss_validation)    \n",
    "        accuracy_validation_results.append(accuracy_validation)\n",
    "        macro_f1_val_results.append(macro_f1_val)\n",
    "        \n",
    "        loss_test_results.append(loss_test)    \n",
    "        accuracy_test_results.append(accuracy_test)\n",
    "        macro_f1_test_results.append(macro_f1_test)\n",
    "        \n",
    "        # print training process\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print('Epoch:', (epoch+1), '|lr:', lr,\n",
    "                  '| train_loss:', loss_train, \n",
    "                  '| train_acc:', accuracy_train, \n",
    "                  '| validation_loss:', loss_validation, \n",
    "                  '| validation_acc:', accuracy_validation)\n",
    "        \n",
    "        save_models(network, output_directory_models, \n",
    "                    loss_train, loss_train_results, \n",
    "                    accuracy_validation, accuracy_validation_results,\n",
    "                    start_time, training_duration_logs)\n",
    "    \n",
    "    # log training time \n",
    "    per_training_duration = time.time() - start_time\n",
    "    log_training_duration.append(per_training_duration)\n",
    "    \n",
    "    # save last_model\n",
    "    output_directory_last = output_directory_models+'last_model.pkl'\n",
    "    torch.save(network.state_dict(), output_directory_last)   # save only the init parameters\n",
    "    \n",
    "    # log history\n",
    "    history = log_history(EPOCH, lr_results, loss_train_results, accuracy_train_results, \n",
    "                          loss_validation_results, accuracy_validation_results,\n",
    "                          loss_test_results, accuracy_test_results,\n",
    "                          output_directory_models)\n",
    "    \n",
    "    plot_learning_history(EPOCH, history, output_directory_models)\n",
    "    \n",
    "    return(history, per_training_duration, log_training_duration)\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e872bfff-f234-4e4b-b392-c08d68882645",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channel = 12\n",
    "dataset_name = \"HAPT\"\n",
    "data_length = 128\n",
    "nb_classes = 6\n",
    "model = If_ConvTransformer(1, input_channel, 64, 5, 3, 2, 128, 1, 0.2, dataset_name, data_length, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "399e3b3e-1b2b-4548-b867-4e06a125ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1,input_channel , data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "baf9192c-41a5-447f-a320-837214d9d234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 12, 128])\n",
      "torch.Size([1, 768, 128])\n"
     ]
    }
   ],
   "source": [
    "t = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3364ebf-7e7c-4978-abe3-d85efcfa2c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Chomp2d is treated as a zero-op.\n",
      "Warning: module IMU_Fusion_Block is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module PositionalEncoding is treated as a zero-op.\n",
      "Warning: module SelfAttention is treated as a zero-op.\n",
      "Warning: module TransformerBlock is treated as a zero-op.\n",
      "Warning: module If_ConvTransformer is treated as a zero-op.\n",
      "torch.Size([1, 64, 12, 128])\n",
      "torch.Size([1, 768, 128])\n",
      "If_ConvTransformer(\n",
      "  559.5 k, 100.000% Params, 159.65 MMac, 94.647% MACs, \n",
      "  (IMU_fusion_block): IMU_Fusion_Block(\n",
      "    2.24 k, 0.401% Params, 899.46 KMac, 0.533% MACs, \n",
      "    (tcn_grav_convs0): Sequential(\n",
      "      320, 0.057% Params, 124.42 KMac, 0.074% MACs, \n",
      "      (0): Conv2d(320, 0.057% Params, 99.84 KMac, 0.059% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (tcn_gyro_convs0): Sequential(\n",
      "      256, 0.046% Params, 98.88 KMac, 0.059% MACs, \n",
      "      (0): Conv2d(256, 0.046% Params, 74.3 KMac, 0.044% MACs, 1, 64, kernel_size=(1, 2), stride=(1, 1), padding=(0, 1))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (tcn_acc_convs0): Sequential(\n",
      "      320, 0.057% Params, 124.42 KMac, 0.074% MACs, \n",
      "      (0): Conv2d(320, 0.057% Params, 99.84 KMac, 0.059% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (tcn_grav_convs1): Sequential(\n",
      "      320, 0.057% Params, 125.95 KMac, 0.075% MACs, \n",
      "      (0): Conv2d(320, 0.057% Params, 101.38 KMac, 0.060% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(2, 2))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (tcn_gyro_convs1): Sequential(\n",
      "      384, 0.069% Params, 150.34 KMac, 0.089% MACs, \n",
      "      (0): Conv2d(384, 0.069% Params, 125.76 KMac, 0.075% MACs, 1, 64, kernel_size=(1, 4), stride=(1, 1), padding=(0, 3))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (tcn_acc_convs1): Sequential(\n",
      "      448, 0.080% Params, 176.64 KMac, 0.105% MACs, \n",
      "      (0): Conv2d(448, 0.080% Params, 152.06 KMac, 0.090% MACs, 1, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))\n",
      "      (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\n",
      "    )\n",
      "    (attention): Sequential(\n",
      "      194, 0.035% Params, 98.82 KMac, 0.059% MACs, \n",
      "      (0): Linear(193, 0.034% Params, 98.31 KMac, 0.058% MACs, in_features=192, out_features=1, bias=True)\n",
      "      (1): PReLU(1, 0.000% Params, 512.0 Mac, 0.000% MACs, num_parameters=1)\n",
      "    )\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, \n",
      "    (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "    (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, \n",
      "    (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "    (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, \n",
      "    (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
      "    (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, )\n",
      "  )\n",
      "  (transition): Sequential(\n",
      "    98.69 k, 17.639% Params, 12.65 MMac, 7.499% MACs, \n",
      "    (0): Conv1d(98.43 k, 17.593% Params, 12.6 MMac, 7.470% MACs, 768, 128, kernel_size=(1,), stride=(1,))\n",
      "    (1): BatchNorm1d(256, 0.046% Params, 32.77 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0, 0.000% Params, 16.38 KMac, 0.010% MACs, )\n",
      "  )\n",
      "  (position_encode): PositionalEncoding(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_block1): TransformerBlock(\n",
      "    197.89 k, 35.369% Params, 25.26 MMac, 14.978% MACs, \n",
      "    (attention): SelfAttention(\n",
      "      65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, \n",
      "      (tokeys): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (toqueries): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (tovalues): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (dropout_attention): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "      (unifyheads): Linear(16.51 k, 2.951% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm1): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      131.71 k, 23.541% Params, 16.84 MMac, 9.986% MACs, \n",
      "      (0): Linear(66.05 k, 11.805% Params, 8.39 MMac, 4.974% MACs, in_features=128, out_features=512, bias=True)\n",
      "      (1): ReLU(0, 0.000% Params, 65.54 KMac, 0.039% MACs, )\n",
      "      (2): Linear(65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm2): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout_forward): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_block2): TransformerBlock(\n",
      "    197.89 k, 35.369% Params, 25.26 MMac, 14.978% MACs, \n",
      "    (attention): SelfAttention(\n",
      "      65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, \n",
      "      (tokeys): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (toqueries): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (tovalues): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False)\n",
      "      (dropout_attention): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "      (unifyheads): Linear(16.51 k, 2.951% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm1): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): Sequential(\n",
      "      131.71 k, 23.541% Params, 16.84 MMac, 9.986% MACs, \n",
      "      (0): Linear(66.05 k, 11.805% Params, 8.39 MMac, 4.974% MACs, in_features=128, out_features=512, bias=True)\n",
      "      (1): ReLU(0, 0.000% Params, 65.54 KMac, 0.039% MACs, )\n",
      "      (2): Linear(65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm2): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout_forward): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "  )\n",
      "  (global_ave_pooling): AdaptiveAvgPool1d(0, 0.000% Params, 16.38 KMac, 0.010% MACs, output_size=1)\n",
      "  (linear): Linear(774, 0.138% Params, 774.0 Mac, 0.000% MACs, in_features=128, out_features=6, bias=True)\n",
      ")\n",
      "Computational complexity:       168.67 MMac\n",
      "Number of parameters:           559.5 k \n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (1,input_channel , data_length), as_strings=True,\n",
    "                                       print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb2330-5bbc-4a3d-afd6-d9a04f27ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"If_ConvTransformer( 559.5 k, 100.000% Params, 159.65 MMac, 94.647% MACs, (IMU_fusion_block): IMU_Fusion_Block( 2.24 k, 0.401% Params, 899.46 KMac, 0.533% MACs, (tcn_grav_convs0): Sequential( 320, 0.057% Params, 124.42 KMac, 0.074% MACs, (0): Conv2d(320, 0.057% Params, 99.84 KMac, 0.059% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (tcn_gyro_convs0): Sequential( 256, 0.046% Params, 98.88 KMac, 0.059% MACs, (0): Conv2d(256, 0.046% Params, 74.3 KMac, 0.044% MACs, 1, 64, kernel_size=(1, 2), stride=(1, 1), padding=(0, 1)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (tcn_acc_convs0): Sequential( 320, 0.057% Params, 124.42 KMac, 0.074% MACs, (0): Conv2d(320, 0.057% Params, 99.84 KMac, 0.059% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (tcn_grav_convs1): Sequential( 320, 0.057% Params, 125.95 KMac, 0.075% MACs, (0): Conv2d(320, 0.057% Params, 101.38 KMac, 0.060% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 4), dilation=(2, 2)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (tcn_gyro_convs1): Sequential( 384, 0.069% Params, 150.34 KMac, 0.089% MACs, (0): Conv2d(384, 0.069% Params, 125.76 KMac, 0.075% MACs, 1, 64, kernel_size=(1, 4), stride=(1, 1), padding=(0, 3)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (tcn_acc_convs1): Sequential( 448, 0.080% Params, 176.64 KMac, 0.105% MACs, (0): Conv2d(448, 0.080% Params, 152.06 KMac, 0.090% MACs, 1, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, ) ) (attention): Sequential( 194, 0.035% Params, 98.82 KMac, 0.059% MACs, (0): Linear(193, 0.034% Params, 98.31 KMac, 0.058% MACs, in_features=192, out_features=1, bias=True) (1): PReLU(1, 0.000% Params, 512.0 Mac, 0.000% MACs, num_parameters=1) ) ) (conv2): Sequential( 20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2)) (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, ) ) (conv3): Sequential( 20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2)) (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, ) ) (conv4): Sequential( 20.67 k, 3.695% Params, 31.85 MMac, 18.883% MACs, (0): Conv2d(20.54 k, 3.672% Params, 31.56 MMac, 18.708% MACs, 64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2)) (1): BatchNorm2d(128, 0.023% Params, 196.61 KMac, 0.117% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(0, 0.000% Params, 98.3 KMac, 0.058% MACs, ) ) (transition): Sequential( 98.69 k, 17.639% Params, 12.65 MMac, 7.499% MACs, (0): Conv1d(98.43 k, 17.593% Params, 12.6 MMac, 7.470% MACs, 768, 128, kernel_size=(1,), stride=(1,)) (1): BatchNorm1d(256, 0.046% Params, 32.77 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(0, 0.000% Params, 16.38 KMac, 0.010% MACs, ) ) (position_encode): PositionalEncoding( 0, 0.000% Params, 0.0 Mac, 0.000% MACs, (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False) ) (transformer_block1): TransformerBlock( 197.89 k, 35.369% Params, 25.26 MMac, 14.978% MACs, (attention): SelfAttention( 65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, (tokeys): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (toqueries): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (tovalues): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (dropout_attention): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False) (unifyheads): Linear(16.51 k, 2.951% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=True) ) (norm1): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True) (mlp): Sequential( 131.71 k, 23.541% Params, 16.84 MMac, 9.986% MACs, (0): Linear(66.05 k, 11.805% Params, 8.39 MMac, 4.974% MACs, in_features=128, out_features=512, bias=True) (1): ReLU(0, 0.000% Params, 65.54 KMac, 0.039% MACs, ) (2): Linear(65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, in_features=512, out_features=128, bias=True) ) (norm2): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True) (dropout_forward): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False) ) (transformer_block2): TransformerBlock( 197.89 k, 35.369% Params, 25.26 MMac, 14.978% MACs, (attention): SelfAttention( 65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, (tokeys): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (toqueries): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (tovalues): Linear(16.38 k, 2.928% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=False) (dropout_attention): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False) (unifyheads): Linear(16.51 k, 2.951% Params, 2.1 MMac, 1.243% MACs, in_features=128, out_features=128, bias=True) ) (norm1): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True) (mlp): Sequential( 131.71 k, 23.541% Params, 16.84 MMac, 9.986% MACs, (0): Linear(66.05 k, 11.805% Params, 8.39 MMac, 4.974% MACs, in_features=128, out_features=512, bias=True) (1): ReLU(0, 0.000% Params, 65.54 KMac, 0.039% MACs, ) (2): Linear(65.66 k, 11.736% Params, 8.39 MMac, 4.973% MACs, in_features=512, out_features=128, bias=True) ) (norm2): LayerNorm(256, 0.046% Params, 16.38 KMac, 0.010% MACs, (128,), eps=1e-05, elementwise_affine=True) (dropout_forward): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False) ) (global_ave_pooling): AdaptiveAvgPool1d(0, 0.000% Params, 16.38 KMac, 0.010% MACs, output_size=1) (linear): Linear(774, 0.138% Params, 774.0 Mac, 0.000% MACs, in_features=128, out_features=6, bias=True) )\"\n",
    "to_profile = [\"(IMU_fusion_block)\",\"(conv2)\",\"(conv3)\",\"(conv4)\",\"(transition)\"]#,\"(transformer_block1)\",\"(transformer_block2)\",\"(global_ave_pooling)\",\"(linear)\"]\n",
    "per = 0\n",
    "for key in to_profile:\n",
    "    extracted_numbers = find_percentage_before_MACs(text,key)\n",
    "    #print(float(extracted_numbers[-1]))\n",
    "    per = per + float(extracted_numbers[-1])\n",
    "per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f05c3cc-fc4e-4802-998d-c098ea86873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.24', '0.401', '899.46', '0.533']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers_from_string(s):\n",
    "    \"\"\"\n",
    "    Extract all numbers from the given string.\n",
    "\n",
    "    :param s: The string to extract numbers from.\n",
    "    :return: A list of numbers (as strings) extracted from the string.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern for matching numbers\n",
    "    pattern = r'\\d+\\.\\d+|\\d+'\n",
    "\n",
    "    # Finding all occurrences of the pattern in the string\n",
    "    numbers = re.findall(pattern, s)\n",
    "\n",
    "    return numbers\n",
    "\n",
    "# Example string\n",
    "text = \"IMU_Fusion_Block( 2.24 k, 0.401% Params, 899.46 KMac, 0.533% MACs\"\n",
    "\n",
    "# Extract numbers\n",
    "extracted_numbers = extract_numbers_from_string(text)\n",
    "print(extracted_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88f0fd11-0bb7-4df9-88e3-250e821f576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['320', '0.057', '124.42', '0.074']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_percentage_before_MACs(text, substring):\n",
    "    \"\"\"\n",
    "    Find the percentage value before the first occurrence of 'MACs' after a given substring.\n",
    "\n",
    "    :param text: The text in which to search.\n",
    "    :param substring: The substring after which to find the percentage.\n",
    "    :return: The percentage found or a message if not found.\n",
    "    \"\"\"\n",
    "    # Constructing the regular expression pattern\n",
    "    pattern = rf\"{re.escape(substring)}.*?(\\d+\\.\\d+%).*?MACs\"\n",
    "    \n",
    "    # Searching for the pattern in the text\n",
    "    match = re.search(pattern, text)\n",
    "    start = match.start()\n",
    "    end = match.end()\n",
    "    text = text[start:end]\n",
    "\n",
    "    return extract_numbers_from_string(text)\n",
    "    # Returning the found percentage or a message if not found\n",
    "    #return match.group(1) if match else \"No match found\"\n",
    "\n",
    "# Example usage\n",
    "text = \"(IMU_fusion_block): IMU_Fusion_Block( 2.24 k, 0.401% Params, 899.46 KMac, 0.533% MACs, (tcn_grav_convs0): Sequential( 320, 0.057% Params, 124.42 KMac, 0.074% MACs, (0): Conv2d(320, 0.057% Params, 99.84 KMac, 0.059% MACs, 1, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2)) (1): Chomp2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, ) (2): ReLU(0, 0.000% Params, 24.58 KMac, 0.015% MACs, )\"\n",
    "substring = \"tcn_grav_convs0\"\n",
    "\n",
    "percentage = find_percentage_before_MACs(text, substring)\n",
    "print(percentage[-4:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc23",
   "language": "python",
   "name": "iswc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
