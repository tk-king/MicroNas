{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7042e0-cf1d-4a78-8888-d434696a9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"IF-ConvTransformer-UbiComp2022-main/src/\")\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "from thop import profile as profile_model\n",
    "from torchlop import profile as profile_layer\n",
    "from thop import clever_format\n",
    "from models.model_builder import model_builder\n",
    "from torchlop.rst_process import write_csv\n",
    "from ptflops import get_model_complexity_info\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "# from model_summary import model_summary\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def find_percentage_before_MACs(text, substring):\n",
    "    \"\"\"\n",
    "    Find the percentage value before the first occurrence of 'MACs' after a given substring.\n",
    "\n",
    "    :param text: The text in which to search.\n",
    "    :param substring: The substring after which to find the percentage.\n",
    "    :return: The percentage found or a message if not found.\n",
    "    \"\"\"\n",
    "    # Constructing the regular expression pattern\n",
    "    pattern = rf\"{re.escape(substring)}.*?(\\d+\\.\\d+%).*?MACs\"\n",
    "    \n",
    "    # Searching for the pattern in the text\n",
    "    match = re.search(pattern, text)\n",
    "    start = match.start()\n",
    "    end = match.end()\n",
    "    text = text[start:end]\n",
    "\n",
    "    return extract_numbers_from_string(text)\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_numbers_from_string(s):\n",
    "    \"\"\"\n",
    "    Extract all numbers from the given string.\n",
    "\n",
    "    :param s: The string to extract numbers from.\n",
    "    :return: A list of numbers (as strings) extracted from the string.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern for matching numbers\n",
    "    pattern = r'\\d+\\.\\d+|\\d+'\n",
    "\n",
    "    # Finding all occurrences of the pattern in the string\n",
    "    numbers = re.findall(pattern, s)\n",
    "\n",
    "    return numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375156-8686-486a-ae3c-8049a8675bfb",
   "metadata": {},
   "source": [
    "# DeepConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b9e3df-0075-4678-9366-cf88d8b812cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the DeepConvLSTM model!\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "args.f_in = 1\n",
    "args.wavelet_filtering = False\n",
    "args.model_type              = \"deepconvlstm\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "# args.cross_channel_interaction_type = \"attn\"\n",
    "# args.cross_channel_aggregation_type = \"FC\"\n",
    "# args.temporal_info_interaction_type = \"lstm\"\n",
    "# args.temporal_info_aggregation_type = \"tnaive\"\n",
    "args.input_length = int(128) # scoda 196   motionsense 128  ucihar 128\n",
    "args.num_classes = 6 #scoda 10   motionsense 6   ucihar 6 \n",
    "args.c_in       = 12  #scoda 30   motionsense 12   ucihar  9\n",
    "args.filter_scaling_factor = 1\n",
    "model = model_builder(args)\n",
    "#model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1fd1bf-bd9e-497d-8972-f6c0e6e2b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ConvBlock is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module DeepConvLSTM is treated as a zero-op.\n",
      "Warning: module model_builder is treated as a zero-op.\n",
      "model_builder(\n",
      "  522.57 k, 100.000% Params, 138.36 MMac, 99.739% MACs, \n",
      "  (model): DeepConvLSTM(\n",
      "    522.57 k, 100.000% Params, 138.36 MMac, 99.739% MACs, \n",
      "    (conv_blocks): ModuleList(\n",
      "      62.02 k, 11.868% Params, 86.73 MMac, 62.515% MACs, \n",
      "      (0): ConvBlock(\n",
      "        20.93 k, 4.005% Params, 30.34 MMac, 21.872% MACs, \n",
      "        (conv1): Conv2d(384, 0.073% Params, 571.39 KMac, 0.412% MACs, 1, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 187.39 KMac, 0.135% MACs, inplace=True)\n",
      "        (conv2): Conv2d(20.54 k, 3.931% Params, 29.58 MMac, 21.325% MACs, 64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        41.09 k, 7.863% Params, 56.38 MMac, 40.643% MACs, \n",
      "        (conv1): Conv2d(20.54 k, 3.931% Params, 28.6 MMac, 20.614% MACs, 64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (relu): ReLU(0, 0.000% Params, 175.1 KMac, 0.126% MACs, inplace=True)\n",
      "        (conv2): Conv2d(20.54 k, 3.931% Params, 27.61 MMac, 19.903% MACs, 64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (lstm_layers): ModuleList(\n",
      "      459.78 k, 87.984% Params, 51.64 MMac, 37.223% MACs, \n",
      "      (0): LSTM(459.78 k, 87.984% Params, 51.64 MMac, 37.223% MACs, 768, 128, batch_first=True)\n",
      "    )\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (fc): Linear(774, 0.148% Params, 774.0 Mac, 0.001% MACs, in_features=128, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       138.73 MMac\n",
      "Number of parameters:           522.57 k\n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (1, args.input_length, args.c_in), as_strings=True,\n",
    "                                       print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69062745-a6fb-4a4e-9e6b-c05091d7bba7",
   "metadata": {},
   "source": [
    "# SHHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7b6b49b-25df-473a-ad32-8af1e9966425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the sahar model!\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "args.f_in = 1\n",
    "args.wavelet_filtering = False\n",
    "args.model_type              = \"sahar\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "# args.cross_channel_interaction_type = \"attn\"\n",
    "# args.cross_channel_aggregation_type = \"FC\"\n",
    "# args.temporal_info_interaction_type = \"lstm\"\n",
    "# args.temporal_info_aggregation_type = \"tnaive\"\n",
    "args.input_length = 128\n",
    "args.num_classes = 12\n",
    "args.c_in       = 9\n",
    "args.filter_scaling_factor = 1\n",
    "model = model_builder(args)\n",
    "model.double();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22d6100e-9086-4e09-ab1f-0eeb95108439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ConvBlock is treated as a zero-op.\n",
      "Warning: module Softmax is treated as a zero-op.\n",
      "Warning: module SensorAttention is treated as a zero-op.\n",
      "Warning: module AttentionLayer is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module EncoderLayer is treated as a zero-op.\n",
      "Warning: module Tanh is treated as a zero-op.\n",
      "Warning: module AttentionWithContext is treated as a zero-op.\n",
      "Warning: module SA_HAR is treated as a zero-op.\n",
      "Warning: module model_builder is treated as a zero-op.\n",
      "model_builder(\n",
      "  424.08 k, 100.000% Params, 56.67 MMac, 99.191% MACs, \n",
      "  (model): SA_HAR(\n",
      "    424.08 k, 100.000% Params, 56.67 MMac, 99.191% MACs, \n",
      "    (first_conv): ConvBlock(\n",
      "      1.67 k, 0.393% Params, 2.07 MMac, 3.621% MACs, \n",
      "      (conv1): Conv2d(768, 0.181% Params, 884.74 KMac, 1.549% MACs, 1, 128, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "      (relu): ReLU(0, 0.000% Params, 148.61 KMac, 0.260% MACs, inplace=True)\n",
      "      (conv2): Conv2d(641, 0.151% Params, 738.43 KMac, 1.292% MACs, 128, 1, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
      "      (norm1): BatchNorm2d(256, 0.060% Params, 294.91 KMac, 0.516% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2): BatchNorm2d(2, 0.000% Params, 2.3 KMac, 0.004% MACs, 1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (SensorAttention): SensorAttention(\n",
      "      1.43 k, 0.336% Params, 1.77 MMac, 3.101% MACs, \n",
      "      (ln): LayerNorm(18, 0.004% Params, 1.15 KMac, 0.002% MACs, (9,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv_1): Conv2d(1.28 k, 0.302% Params, 1.47 MMac, 2.581% MACs, 1, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "      (conv_f): Conv2d(129, 0.030% Params, 148.61 KMac, 0.260% MACs, 128, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
      "      (relu): ReLU(0, 0.000% Params, 147.46 KMac, 0.258% MACs, )\n",
      "      (softmax): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=3)\n",
      "    )\n",
      "    (conv1d): Conv1d(1.28 k, 0.302% Params, 163.84 KMac, 0.287% MACs, 9, 128, kernel_size=(1,), stride=(1,))\n",
      "    (EncoderLayer1): EncoderLayer(\n",
      "      198.14 k, 46.723% Params, 25.27 MMac, 44.221% MACs, \n",
      "      (attention): AttentionLayer(\n",
      "        65.92 k, 15.544% Params, 8.39 MMac, 14.683% MACs, \n",
      "        (query_projection): Linear(16.38 k, 3.863% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=False)\n",
      "        (key_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "        (value_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "        (out_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (dropout1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "      (layernorm1): LayerNorm(256, 0.060% Params, 16.38 KMac, 0.029% MACs, (128,), eps=1e-06, elementwise_affine=True)\n",
      "      (ffn1): Linear(66.05 k, 15.574% Params, 8.39 MMac, 14.683% MACs, in_features=128, out_features=512, bias=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.115% MACs, )\n",
      "      (ffn2): Linear(65.66 k, 15.484% Params, 8.39 MMac, 14.683% MACs, in_features=512, out_features=128, bias=True)\n",
      "      (layernorm2): LayerNorm(256, 0.060% Params, 16.38 KMac, 0.029% MACs, (128,), eps=1e-06, elementwise_affine=True)\n",
      "      (dropout2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "    )\n",
      "    (EncoderLayer2): EncoderLayer(\n",
      "      198.14 k, 46.723% Params, 25.27 MMac, 44.221% MACs, \n",
      "      (attention): AttentionLayer(\n",
      "        65.92 k, 15.544% Params, 8.39 MMac, 14.683% MACs, \n",
      "        (query_projection): Linear(16.38 k, 3.863% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=False)\n",
      "        (key_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "        (value_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "        (out_projection): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (dropout1): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "      (layernorm1): LayerNorm(256, 0.060% Params, 16.38 KMac, 0.029% MACs, (128,), eps=1e-06, elementwise_affine=True)\n",
      "      (ffn1): Linear(66.05 k, 15.574% Params, 8.39 MMac, 14.683% MACs, in_features=128, out_features=512, bias=True)\n",
      "      (relu): ReLU(0, 0.000% Params, 65.54 KMac, 0.115% MACs, )\n",
      "      (ffn2): Linear(65.66 k, 15.484% Params, 8.39 MMac, 14.683% MACs, in_features=512, out_features=128, bias=True)\n",
      "      (layernorm2): LayerNorm(256, 0.060% Params, 16.38 KMac, 0.029% MACs, (128,), eps=1e-06, elementwise_affine=True)\n",
      "      (dropout2): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "    )\n",
      "    (AttentionWithContext): AttentionWithContext(\n",
      "      16.64 k, 3.924% Params, 2.11 MMac, 3.699% MACs, \n",
      "      (W): Linear(16.51 k, 3.894% Params, 2.1 MMac, 3.671% MACs, in_features=128, out_features=128, bias=True)\n",
      "      (tanh): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (u): Linear(128, 0.030% Params, 16.38 KMac, 0.029% MACs, in_features=128, out_features=1, bias=False)\n",
      "    )\n",
      "    (fc1): Linear(6.19 k, 1.460% Params, 6.19 KMac, 0.011% MACs, in_features=128, out_features=48, bias=True)\n",
      "    (relu): ReLU(0, 0.000% Params, 16.43 KMac, 0.029% MACs, )\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.2, inplace=False)\n",
      "    (fc_out): Linear(588, 0.139% Params, 588.0 Mac, 0.001% MACs, in_features=48, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       57.13 MMac\n",
      "Number of parameters:           424.08 k\n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (1, args.input_length, args.c_in), as_strings=True,\n",
    "                                       print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbacfb-8283-42f3-9f63-3f0fd840842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conv\n",
    "SensorAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c1cc0-0456-4bbc-bb8a-5c2c1783184c",
   "metadata": {},
   "source": [
    "# Tiny HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ac2d03-250b-428b-a6f7-e9d74e43bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Build the TinyHAR model!\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "args.f_in = 1\n",
    "args.wavelet_filtering = False\n",
    "args.model_type              = \"tinyhar\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "args.cross_channel_interaction_type = \"attn\"\n",
    "args.cross_channel_aggregation_type = \"FC\"\n",
    "args.temporal_info_interaction_type = \"lstm\"\n",
    "args.temporal_info_aggregation_type = \"tnaive\"\n",
    "args.input_length = int(128) # scoda 196   motionsense 128  ucihar 128\n",
    "args.num_classes = 6 #scoda 10   motionsense 6   ucihar 6 \n",
    "args.c_in       = 9  #scoda 30   motionsense 12   ucihar  9\n",
    "args.filter_scaling_factor = 1\n",
    "model = model_builder(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c3dd22-3bde-4d5a-9a28-fc5447189e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module SelfAttention_interaction is treated as a zero-op.\n",
      "Warning: module FC is treated as a zero-op.\n",
      "Warning: module temporal_LSTM is treated as a zero-op.\n",
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module Tanh is treated as a zero-op.\n",
      "Warning: module Softmax is treated as a zero-op.\n",
      "Warning: module Temporal_Weighted_Aggregation is treated as a zero-op.\n",
      "Warning: module TinyHAR_Model is treated as a zero-op.\n",
      "Warning: module model_builder is treated as a zero-op.\n",
      "model_builder(\n",
      "  298.18 k, 99.999% Params, 35.84 MMac, 98.819% MACs, \n",
      "  (model): TinyHAR_Model(\n",
      "    298.18 k, 99.999% Params, 35.84 MMac, 98.819% MACs, \n",
      "    (layers_conv): ModuleList(\n",
      "      62.53 k, 20.970% Params, 27.14 MMac, 74.847% MACs, \n",
      "      (0): Sequential(\n",
      "        512, 0.172% Params, 642.82 KMac, 1.773% MACs, \n",
      "        (0): Conv2d(384, 0.129% Params, 428.54 KMac, 1.182% MACs, 1, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 71.42 KMac, 0.197% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(128, 0.043% Params, 142.85 KMac, 0.394% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        20.67 k, 6.933% Params, 11.2 MMac, 30.876% MACs, \n",
      "        (0): Conv2d(20.54 k, 6.890% Params, 11.09 MMac, 30.590% MACs, 64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 34.56 KMac, 0.095% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(128, 0.043% Params, 69.12 KMac, 0.191% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        20.67 k, 6.933% Params, 10.45 MMac, 28.818% MACs, \n",
      "        (0): Conv2d(20.54 k, 6.890% Params, 10.35 MMac, 28.551% MACs, 64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 32.26 KMac, 0.089% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(128, 0.043% Params, 64.51 KMac, 0.178% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        20.67 k, 6.933% Params, 4.85 MMac, 13.380% MACs, \n",
      "        (0): Conv2d(20.54 k, 6.890% Params, 4.81 MMac, 13.256% MACs, 64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 14.98 KMac, 0.041% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(128, 0.043% Params, 29.95 KMac, 0.083% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (channel_interaction): SelfAttention_interaction(\n",
      "      12.29 k, 4.121% Params, 2.88 MMac, 7.929% MACs, \n",
      "      (query): Linear(4.1 k, 1.374% Params, 958.46 KMac, 2.643% MACs, in_features=64, out_features=64, bias=False)\n",
      "      (key): Linear(4.1 k, 1.374% Params, 958.46 KMac, 2.643% MACs, in_features=64, out_features=64, bias=False)\n",
      "      (value): Linear(4.1 k, 1.374% Params, 958.46 KMac, 2.643% MACs, in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (channel_fusion): FC(\n",
      "      73.86 k, 24.769% Params, 1.92 MMac, 5.286% MACs, \n",
      "      (fc): Linear(73.86 k, 24.769% Params, 1.92 MMac, 5.286% MACs, in_features=576, out_features=128, bias=True)\n",
      "    )\n",
      "    (activation): ReLU(0, 0.000% Params, 3.33 KMac, 0.009% MACs, )\n",
      "    (temporal_interaction): temporal_LSTM(\n",
      "      132.1 k, 44.300% Params, 3.47 MMac, 9.562% MACs, \n",
      "      (lstm): LSTM(132.1 k, 44.300% Params, 3.47 MMac, 9.562% MACs, 128, 128, batch_first=True)\n",
      "    )\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "    (temporal_fusion): Temporal_Weighted_Aggregation(\n",
      "      16.64 k, 5.580% Params, 429.44 KMac, 1.184% MACs, \n",
      "      (fc_1): Linear(16.51 k, 5.538% Params, 426.11 KMac, 1.175% MACs, in_features=128, out_features=128, bias=True)\n",
      "      (weighs_activation): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (fc_2): Linear(128, 0.043% Params, 3.33 KMac, 0.009% MACs, in_features=128, out_features=1, bias=False)\n",
      "      (sm): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      "    )\n",
      "    (prediction): Linear(774, 0.260% Params, 774.0 Mac, 0.002% MACs, in_features=128, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       36.27 MMac\n",
      "Number of parameters:           298.18 k\n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (1, args.input_length, args.c_in), as_strings=True,\n",
    "                                       print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f1fbe-8dfd-421e-9abf-21391dd4ada5",
   "metadata": {},
   "source": [
    "# Attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bbf9e3e-3fe9-4390-bc66-5666c12fc5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the AttendDiscriminate model!\n"
     ]
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "args.f_in = 1\n",
    "args.wavelet_filtering = False\n",
    "args.model_type = \"attend\"\n",
    "args.input_length = int(128) # scoda 196   motionsense 128  ucihar 128\n",
    "args.num_classes = 6 #scoda 10   motionsense 6   ucihar 6 \n",
    "args.c_in       = 9  #scoda 30   motionsense 12   ucihar  9\n",
    "args.filter_scaling_factor = 0.30\n",
    "model = model_builder(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552a6ba-502d-4e43-af5e-3edf88753fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa00ceca-d696-4efc-a55f-a605b72b87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Dropout is treated as a zero-op.\n",
      "Warning: module Softmax is treated as a zero-op.\n",
      "Warning: module TemporalAttention is treated as a zero-op.\n",
      "Warning: module SelfAttention is treated as a zero-op.\n",
      "Warning: module FeatureExtractor is treated as a zero-op.\n",
      "Warning: module Classifier is treated as a zero-op.\n",
      "Warning: module AttendDiscriminate is treated as a zero-op.\n",
      "Warning: module model_builder is treated as a zero-op.\n",
      "model_builder(\n",
      "  35.56 k, 99.997% Params, 1.05 MMac, 97.012% MACs, \n",
      "  (model): AttendDiscriminate(\n",
      "    35.56 k, 99.997% Params, 1.05 MMac, 97.012% MACs, \n",
      "    (fe): FeatureExtractor(\n",
      "      35.32 k, 99.339% Params, 1.05 MMac, 96.991% MACs, \n",
      "      (conv1): Conv2d(114, 0.321% Params, 49.48 KMac, 4.585% MACs, 1, 19, kernel_size=(5, 1), stride=(2, 1))\n",
      "      (conv2): Conv2d(1.82 k, 5.130% Params, 370.27 KMac, 34.315% MACs, 19, 19, kernel_size=(5, 1), stride=(2, 1))\n",
      "      (conv3): Conv2d(1.82 k, 5.130% Params, 165.98 KMac, 15.383% MACs, 19, 19, kernel_size=(5, 1), stride=(2, 1))\n",
      "      (conv4): Conv2d(1.82 k, 5.130% Params, 114.91 KMac, 10.650% MACs, 19, 19, kernel_size=(5, 1), stride=(1, 1))\n",
      "      (activation): ReLU(0, 0.000% Params, 15.03 KMac, 1.393% MACs, )\n",
      "      (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "      (rnn): GRU(28.61 k, 80.474% Params, 262.31 KMac, 24.310% MACs, 133, 38, num_layers=2, dropout=0.25)\n",
      "      (ta): TemporalAttention(\n",
      "        39, 0.110% Params, 343.0 Mac, 0.032% MACs, \n",
      "        (fc): Linear(39, 0.110% Params, 343.0 Mac, 0.032% MACs, in_features=38, out_features=1, bias=True)\n",
      "        (sm): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=0)\n",
      "      )\n",
      "      (sa): SelfAttention(\n",
      "        1.08 k, 3.046% Params, 68.23 KMac, 6.323% MACs, \n",
      "        (query): Conv1d(361, 1.015% Params, 22.74 KMac, 2.108% MACs, 19, 19, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (key): Conv1d(361, 1.015% Params, 22.74 KMac, 2.108% MACs, 19, 19, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (value): Conv1d(361, 1.015% Params, 22.74 KMac, 2.108% MACs, 19, 19, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (classifier): Classifier(\n",
      "      234, 0.658% Params, 234.0 Mac, 0.022% MACs, \n",
      "      (fc): Linear(234, 0.658% Params, 234.0 Mac, 0.022% MACs, in_features=38, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Computational complexity:       1.08 MMac\n",
      "Number of parameters:           35.56 k \n"
     ]
    }
   ],
   "source": [
    "macs, params = get_model_complexity_info(model, (1, args.input_length, args.c_in), as_strings=True,\n",
    "                                       print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b17cf3c-982e-4da3-9161-edee4e0be099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_summary(model, (1, args.input_length, args.c_in), query_granularity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c2647-4a99-4954-9d3d-5155e2055444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408a6d1e-288d-45b2-8ef2-d0ced217f37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "323.253M 519.885K\n"
     ]
    }
   ],
   "source": [
    "# thop\n",
    "input = torch.randn(1, 1, args.input_length, args.c_in)\n",
    "macs, params = profile_model(model, inputs=(input, ), ret_layer_info=False)\n",
    "macs, params = clever_format([macs, params], \"%.3f\")\n",
    "print(macs,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd87d21-c8c6-4da4-b467-1d40bb330b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b91b43-dcdf-44dd-bd8f-24634087bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchlop\n",
    "macs, params, layer_infos = profile_layer(model, inputs=(input, ))\n",
    "\n",
    "csv_file='profile_2.csv'\n",
    "write_csv(csv_file,layer_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e59503-f4e0-432e-b52f-871abef971c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c86ba5-09e1-43ae-88e1-23fcd57ea7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fvcore\n",
    "flops = FlopCountAnalysis(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f731f320-64d2-423c-963e-d390c950efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::softmax encountered 241 time(s)\n",
      "Unsupported operator aten::mul encountered 241 time(s)\n",
      "Unsupported operator aten::add encountered 240 time(s)\n",
      "Unsupported operator aten::gru encountered 1 time(s)\n",
      "Unsupported operator aten::sum encountered 1 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "220709376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a20fc8d-94c6-4ef4-9b41-3ad6c915a909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': Counter({'conv': 216253440, 'bmm': 4423680, 'linear': 32256}),\n",
       " 'model': Counter({'conv': 216253440, 'bmm': 4423680, 'linear': 32256}),\n",
       " 'model.fe': Counter({'conv': 216253440, 'bmm': 4423680, 'linear': 30720}),\n",
       " 'model.fe.conv1': Counter({'conv': 967680}),\n",
       " 'model.fe.conv2': Counter({'conv': 60948480}),\n",
       " 'model.fe.conv3': Counter({'conv': 59965440}),\n",
       " 'model.fe.conv4': Counter({'conv': 58982400}),\n",
       " 'model.fe.activation': Counter(),\n",
       " 'model.fe.dropout': Counter(),\n",
       " 'model.fe.rnn': Counter(),\n",
       " 'model.fe.ta': Counter({'linear': 30720}),\n",
       " 'model.fe.ta.fc': Counter({'linear': 30720}),\n",
       " 'model.fe.ta.sm': Counter(),\n",
       " 'model.fe.sa': Counter({'conv': 35389440, 'bmm': 4423680}),\n",
       " 'model.fe.sa.query': Counter({'conv': 11796480}),\n",
       " 'model.fe.sa.key': Counter({'conv': 11796480}),\n",
       " 'model.fe.sa.value': Counter({'conv': 11796480}),\n",
       " 'model.dropout': Counter(),\n",
       " 'model.classifier': Counter({'linear': 1536}),\n",
       " 'model.classifier.fc': Counter({'linear': 1536})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops.by_module_and_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fd1444-8d85-42d0-960d-30fdd9c39c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                 | #parameters or shape   | #flops     |\n",
      "|:-----------------------|:-----------------------|:-----------|\n",
      "| model                  | 0.52M                  | 0.221G     |\n",
      "|  fe                    |  0.518M                |  0.221G    |\n",
      "|   fe.conv1             |   0.384K               |   0.968M   |\n",
      "|    fe.conv1.weight     |    (64, 1, 5, 1)       |            |\n",
      "|    fe.conv1.bias       |    (64,)               |            |\n",
      "|   fe.conv2             |   20.544K              |   60.948M  |\n",
      "|    fe.conv2.weight     |    (64, 64, 5, 1)      |            |\n",
      "|    fe.conv2.bias       |    (64,)               |            |\n",
      "|   fe.conv3             |   20.544K              |   59.965M  |\n",
      "|    fe.conv3.weight     |    (64, 64, 5, 1)      |            |\n",
      "|    fe.conv3.bias       |    (64,)               |            |\n",
      "|   fe.conv4             |   20.544K              |   58.982M  |\n",
      "|    fe.conv4.weight     |    (64, 64, 5, 1)      |            |\n",
      "|    fe.conv4.bias       |    (64,)               |            |\n",
      "|   fe.rnn               |   0.444M               |   0        |\n",
      "|    fe.rnn.weight_ih_l0 |    (384, 768)          |            |\n",
      "|    fe.rnn.weight_hh_l0 |    (384, 128)          |            |\n",
      "|    fe.rnn.bias_ih_l0   |    (384,)              |            |\n",
      "|    fe.rnn.bias_hh_l0   |    (384,)              |            |\n",
      "|    fe.rnn.weight_ih_l1 |    (384, 128)          |            |\n",
      "|    fe.rnn.weight_hh_l1 |    (384, 128)          |            |\n",
      "|    fe.rnn.bias_ih_l1   |    (384,)              |            |\n",
      "|    fe.rnn.bias_hh_l1   |    (384,)              |            |\n",
      "|   fe.ta.fc             |   0.129K               |   30.72K   |\n",
      "|    fe.ta.fc.weight     |    (1, 128)            |            |\n",
      "|    fe.ta.fc.bias       |    (1,)                |            |\n",
      "|   fe.sa                |   12.289K              |   39.813M  |\n",
      "|    fe.sa.gamma         |    (1,)                |            |\n",
      "|    fe.sa.query         |    4.096K              |    11.796M |\n",
      "|    fe.sa.key           |    4.096K              |    11.796M |\n",
      "|    fe.sa.value         |    4.096K              |    11.796M |\n",
      "|  classifier.fc         |  1.548K                |  1.536K    |\n",
      "|   classifier.fc.weight |   (12, 128)            |            |\n",
      "|   classifier.fc.bias   |   (12,)                |            |\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import flop_count_table\n",
    "print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e2198-a113-4cad-a833-270fb084cff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65a843-8019-4d0b-ba56-5aa13b961eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1aa3a-d5d5-4987-a450-3d6c051405be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ad5c9-f4b3-4da3-b01e-edd287767e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc23",
   "language": "python",
   "name": "iswc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
