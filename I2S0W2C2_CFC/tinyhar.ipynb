{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5658cbde-8b6c-4ee0-b48c-2a2b12133261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ad5ff6-9a7b-4eff-958a-95e14cbae471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SelfAttention_interaction(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, n_channels):\n",
    "        super(SelfAttention_interaction, self).__init__()\n",
    "\n",
    "        self.query         = nn.Linear(n_channels, n_channels, bias=False)\n",
    "        self.key           = nn.Linear(n_channels, n_channels, bias=False)\n",
    "        self.value         = nn.Linear(n_channels, n_channels, bias=False)\n",
    "        self.gamma         = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "\n",
    "        #self.fc1            = nn.Linear(n_channels, n_channels, bias=False)\n",
    "        #self.fc_activation = nn.ReLU() \n",
    "        #self.fc2            = nn.Linear(n_channels, n_channels, bias=False)\n",
    "        #self.beta         = nn.Parameter(torch.tensor([0.]))\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 输入尺寸是 batch  sensor_channel feature_dim\n",
    "        #print(x.shape)\n",
    "\n",
    "        f, g, h = self.query(x), self.key(x), self.value(x)\n",
    "        \n",
    "        beta = F.softmax(torch.bmm(f, g.permute(0, 2, 1).contiguous()), dim=1)\n",
    "\n",
    "        o = self.gamma * torch.bmm(h.permute(0, 2, 1).contiguous(), beta) + x.permute(0, 2, 1).contiguous()\n",
    "        o = o.permute(0, 2, 1).contiguous()\n",
    "\n",
    "\n",
    "        #o = self.beta  * self.fc2(self.fc_activation(self.fc1(o)))  +  o\n",
    "        # 输出是 batch  sensor_channel feature_dim 1 \n",
    "        return o\n",
    "\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 16, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class Transformer_interaction(nn.Module):\n",
    "    def __init__(self, sensor_channel, dim, depth=1, heads=4, dim_head=16, mlp_dim=16, dropout = 0.):\n",
    "        super(Transformer_interaction,self).__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class seperate_FC_interaction(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(seperate_FC_interaction, self).__init__()\n",
    "        self.fc_filter = nn.Linear(filter_num ,filter_num)\n",
    "        self.fc_channel  = nn.Linear(sensor_channel ,sensor_channel)\n",
    "    def forward(self,x):\n",
    "        # input b C F \n",
    "        #x = x.permute(0,1,3,2)\n",
    "        x = self.fc_channel(x.permute(0,2,1)).permute(0,2,1)#.squeeze(3)\n",
    "        x = self.fc_filter(x)#.permute(0,2,1)\n",
    "        return x\n",
    "\n",
    "crosschannel_interaction = {\"attn\":SelfAttention_interaction,\n",
    "                            \"transformer\": Transformer_interaction,\n",
    "                            \"identity\": Identity,\n",
    "                            \"FCinter\" : seperate_FC_interaction}\n",
    "\n",
    "class FilterWeighted_Aggregation(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, n_channels):\n",
    "        super(FilterWeighted_Aggregation, self).__init__()\n",
    "        self.value_projection = nn.Linear(n_channels, n_channels)\n",
    "        self.value_activation = nn.ReLU() \n",
    "        \n",
    "        self.weight_projection = nn.Linear(n_channels, n_channels)\n",
    "        self.weighs_activation = nn.Tanh() \n",
    "        self.softmatx = nn.Softmax(dim=1)        \n",
    "        #self.fc            = nn.Linear(n_channels, n_channels)\n",
    "        #self.fc_activation = nn.ReLU() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 输入是 batch  sensor_channel feature_dim\n",
    "\n",
    "\n",
    "        weights = self.weighs_activation(self.weight_projection(x))\n",
    "        weights = self.softmatx(weights)\n",
    "        \n",
    "        values  = self.value_activation(self.value_projection(x))\n",
    "\n",
    "        values  = torch.mul(values, weights)\n",
    "        o       = torch.sum(values,dim=1)\n",
    "\n",
    "\n",
    "        #o       = self.fc_activation(self.fc(o))\n",
    "        # 返回是 batch feature_dim\n",
    "        return o\n",
    "\n",
    "class NaiveWeighted_Aggregation(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention module\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, hidden_dim):\n",
    "        super(NaiveWeighted_Aggregation, self).__init__()\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 输入是 batch  sensor_channel feature_dim\n",
    "        #   B C F\n",
    "\n",
    "        out = self.fc(x).squeeze(2)\n",
    "\n",
    "        weights_att = self.sm(out).unsqueeze(2)\n",
    "        context = torch.sum(weights_att * x, 1)\n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Weighted_Aggregation(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention module\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, hidden_dim):\n",
    "        super(Weighted_Aggregation, self).__init__()\n",
    "        self.weight_projection = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.weighs_activation = nn.Tanh() \n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 输入是 batch  sensor_channel feature_dim\n",
    "        #   B C F\n",
    "        x = self.weighs_activation(self.weight_projection(x))\n",
    "        out = self.fc(x).squeeze(2)\n",
    "\n",
    "        weights_att = self.sm(out).unsqueeze(2)\n",
    "        context = torch.sum(weights_att * x, 1)\n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FC(nn.Module):\n",
    "\n",
    "    def __init__(self, channel_in, channel_out):\n",
    "        super(FC, self).__init__()\n",
    "        self.fc = nn.Linear(channel_in ,channel_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return(x)\n",
    "\n",
    "class seperate_FC_channel_first(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(seperate_FC_channel_first, self).__init__()\n",
    "        self.fc_channel = nn.Linear(sensor_channel ,1)\n",
    "        self.fc_filter  = nn.Linear(filter_num ,filter_num)\n",
    "    def forward(self,x):\n",
    "        # input b L C F \n",
    "        x = x.permute(0,1,3,2)\n",
    "        x = self.fc_channel(x).squeeze(3)\n",
    "        x = self.fc_filter(x)\n",
    "        return x\n",
    "\n",
    "class seperate_FC_filter_first(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(seperate_FC_filter_first, self).__init__()\n",
    "        self.fc_filter = nn.Linear(filter_num ,1)\n",
    "        self.fc_channel  = nn.Linear(sensor_channel ,filter_num)\n",
    "        self.activation = nn.ReLU() \n",
    "    def forward(self,x):\n",
    "        # input b L C F \n",
    "        #x = x.permute(0,1,3,2)\n",
    "        x = self.fc_filter(x).squeeze(3)\n",
    "        x = self.fc_channel(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class seperate_FC_filter_first_v2(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(seperate_FC_filter_first_v2, self).__init__()\n",
    "        #self.fc_filter_1 = nn.Linear(filter_num ,int(filter_num/2))\n",
    "        #self.fc_channel_1  = nn.Linear(sensor_channel ,max(5, int(sensor_channel/2)))\n",
    "        #self.activation = nn.ReLU() \n",
    "\n",
    "        #self.fc_filter_2 = nn.Linear(int(filter_num/2),1)\n",
    "        #self.fc_channel_2  = nn.Linear(max(5, int(sensor_channel/2)) ,filter_num)\n",
    "\n",
    "        self.fc_filter_1 = nn.Linear(filter_num ,filter_num)\n",
    "        self.fc_channel_1  = nn.Linear(sensor_channel ,sensor_channel)\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "        self.fc_filter_2 = nn.Linear(filter_num,1)\n",
    "        self.fc_channel_2  = nn.Linear(sensor_channel ,filter_num)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # input b L C F \n",
    "        #x = x.permute(0,1,3,2)\n",
    "\n",
    "        x = self.activation(self.fc_filter_1(x))#.squeeze(3)\n",
    "        x = x.permute(0,1,3,2)\n",
    "        x = self.activation(self.fc_channel_1(x))\n",
    "        x = x.permute(0,1,3,2)\n",
    "\n",
    "        x = self.fc_filter_2(x).squeeze(3)\n",
    "        x = self.activation(self.fc_channel_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FC_Weighted_Aggregation(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention module\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, hidden_dim):\n",
    "        super(FC_Weighted_Aggregation, self).__init__()\n",
    "\t\t\n",
    "        self.fc_filter_1 = nn.Linear(hidden_dim ,hidden_dim)\n",
    "        self.fc_channel_1  = nn.Linear(sensor_channel ,sensor_channel)\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 输入是 batch  sensor_channel feature_dim\n",
    "        #   B C F\n",
    "        x   = self.activation(self.fc_filter_1(x)).permute(0,2,1)\n",
    "        x   = self.activation(self.fc_channel_1(x)).permute(0,2,1)\n",
    "\n",
    "        out = self.fc(x).squeeze(2)\n",
    "\n",
    "        weights_att = self.sm(out).unsqueeze(2)\n",
    "        context = torch.sum(weights_att * x, 1)\n",
    "        return context\n",
    "\n",
    "\n",
    "crosschannel_aggregation = {\"filter\": FilterWeighted_Aggregation,\n",
    "                            \"naive\" : NaiveWeighted_Aggregation,\n",
    "                            \"FCnaive\":FC_Weighted_Aggregation,\n",
    "                            \"naive2\": Weighted_Aggregation,\n",
    "                            \"FC\" : FC,\n",
    "                            \"SFCF\" : seperate_FC_filter_first,\n",
    "                            \"SFCF2\": seperate_FC_filter_first_v2,\n",
    "                            \"SFCC\" : seperate_FC_channel_first}\n",
    "\n",
    "\n",
    "\n",
    "class temporal_GRU(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(temporal_GRU, self).__init__()\n",
    "        self.rnn = nn.GRU(\n",
    "            filter_num,\n",
    "            filter_num,\n",
    "            1,\n",
    "            bidirectional=False,\n",
    "            batch_first = True\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Batch length Filter\n",
    "        outputs, h = self.rnn(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class temporal_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, filter_num):\n",
    "        super(temporal_LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(filter_num, \n",
    "                            filter_num, \n",
    "                            batch_first =True)\n",
    "    def forward(self, x):\n",
    "        # Batch length Filter\n",
    "        outputs, h = self.lstm(x)\n",
    "        return outputs\n",
    "\n",
    "class temporal_conv_1d(nn.Module):\n",
    "    def __init__(self, sensor_channel, filter_num, nb_layers=2):\n",
    "        super(temporal_conv_1d, self).__init__()\n",
    "        filter_num_list=[filter_num]\n",
    "        filter_num_step=int(filter_num/nb_layers)\n",
    "        for i in range(nb_layers-1):\n",
    "            #filter_num_list.append((1+i)*filter_num_step)\n",
    "            filter_num_list.append(filter_num)\n",
    "        #filter_num_list.append(1)\n",
    "        filter_num_list.append(filter_num)\n",
    "        layers_conv = []\n",
    "        for i in range(nb_layers):\n",
    "            in_channel  = filter_num_list[i]\n",
    "            out_channel = filter_num_list[i+1]\n",
    "            layers_conv.append(nn.Sequential(\n",
    "                nn.Conv1d(in_channel, out_channel, 5, padding=\"same\",padding_mode=\"replicate\"),\n",
    "                nn.ReLU(inplace=True)))\n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1)\n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        return x\n",
    "\n",
    "temporal_interaction = {\"gru\": temporal_GRU,\n",
    "                        \"lstm\": temporal_LSTM,\n",
    "                        \"attn\"   :SelfAttention_interaction,\n",
    "                        \"transformer\": Transformer_interaction,\n",
    "                        \"identity\" : Identity,\n",
    "                        \"conv\"      : temporal_conv_1d}\n",
    "\n",
    "class Temporal_Weighted_Aggregation(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal attention module\n",
    "    \"\"\"\n",
    "    def __init__(self, sensor_channel, hidden_dim):\n",
    "        super(Temporal_Weighted_Aggregation, self).__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.weighs_activation = nn.Tanh() \n",
    "        self.fc_2 = nn.Linear(hidden_dim, 1, bias=False)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "        self.gamma         = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 输入是 batch  sensor_channel feature_dim\n",
    "        #   B C F\n",
    "\n",
    "        out = self.weighs_activation(self.fc_1(x))\n",
    "\n",
    "        out = self.fc_2(out).squeeze(2)\n",
    "\n",
    "        weights_att = self.sm(out).unsqueeze(2)\n",
    "\n",
    "        context = torch.sum(weights_att * x, 1)\n",
    "        context = x[:, -1, :] + self.gamma * context\n",
    "        return context\n",
    "\n",
    "temmporal_aggregation = {\"filter\": FilterWeighted_Aggregation,\n",
    "                         \"naive\" : NaiveWeighted_Aggregation,\n",
    "                         \"tnaive\" : Temporal_Weighted_Aggregation,\n",
    "                         \"FC\" : FC,\n",
    "                         \"identiry\":Identity}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TinyHAR_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape ,\n",
    "        number_class , \n",
    "\n",
    "        filter_num,\n",
    "        nb_conv_layers                 = 4,        \n",
    "        filter_size                    = 5,\n",
    "        \n",
    "        cross_channel_interaction_type = \"attn\",    # attn  transformer  identity\n",
    "        cross_channel_aggregation_type = \"filter\",  # filter  naive  FC\n",
    "        temporal_info_interaction_type = \"gru\",     # gru  lstm  attn  transformer  identity\n",
    "        temporal_info_aggregation_type = \"FC\",      # naive  filter  FC \n",
    "\n",
    "        dropout = 0.1,\n",
    "\n",
    "        activation = \"ReLU\",\n",
    "\n",
    "    ):\n",
    "        super(TinyHAR_Model, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.cross_channel_interaction_type = cross_channel_interaction_type\n",
    "        self.cross_channel_aggregation_type = cross_channel_aggregation_type\n",
    "        self.temporal_info_interaction_type = temporal_info_interaction_type\n",
    "        self.temporal_info_aggregation_type = temporal_info_aggregation_type\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 1 , ============= Channel wise Feature Extraction =============================        \n",
    "        输入的格式为  Batch, filter_num, length, Sensor_channel        \n",
    "        输出格式为为  Batch, filter_num, downsampling_length, Sensor_channel\n",
    "        \"\"\"\n",
    "        filter_num_list=[1]\n",
    "        filter_num_step=int(filter_num/nb_conv_layers)\n",
    "        for i in range(nb_conv_layers-1):\n",
    "            #filter_num_list.append((1+i)*filter_num_step)\n",
    "            filter_num_list.append(filter_num)\n",
    "        filter_num_list.append(filter_num)\n",
    "        filter_size_list = [5,5,3,3]\n",
    "        layers_conv = []\n",
    "        for i in range(nb_conv_layers):\n",
    "            in_channel  = filter_num_list[i]\n",
    "            out_channel = filter_num_list[i+1]\n",
    "            if i%2 == 1:\n",
    "                layers_conv.append(nn.Sequential(\n",
    "                    nn.Conv2d(in_channel, out_channel, (filter_size_list[i], 1),(2,1)),\n",
    "                    nn.ReLU(inplace=True),#))#,\n",
    "                    nn.BatchNorm2d(out_channel)))\n",
    "            else:\n",
    "                layers_conv.append(nn.Sequential(\n",
    "                    nn.Conv2d(in_channel, out_channel, (filter_size_list[i], 1),(2,1)),\n",
    "                    nn.ReLU(inplace=True),#))#,\n",
    "                    nn.BatchNorm2d(out_channel)))\n",
    "        self.layers_conv = nn.ModuleList(layers_conv)\n",
    "        # 这是给最后时间维度 vectorize的时候用的\n",
    "        downsampling_length = self.get_the_shape(input_shape)        \n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        PART2 , ================ Cross Channel interaction  =================================\n",
    "        这里可供选择的  attn   transformer  itentity\n",
    "        输出格式为  Batch, filter_num, downsampling_length, Sensor_channel\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.channel_interaction = crosschannel_interaction[cross_channel_interaction_type](input_shape[3], filter_num)\n",
    "        # 这里还是 B F C L  需要permute++++++++++++++\n",
    "\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        PART3 , =============== Cross Channel Fusion  ====================================\n",
    "        这里可供选择的  filter   naive  FC\n",
    "\n",
    "        输出格式为  Batch, downsampling_length, filter_num\n",
    "        \"\"\"\n",
    "        if cross_channel_aggregation_type == \"FC\":\n",
    "            # 这里需要reshape为 B L C*F++++++++++++++\n",
    "            self.channel_fusion = crosschannel_aggregation[cross_channel_aggregation_type](input_shape[3]*filter_num,2*filter_num)\n",
    "        elif cross_channel_aggregation_type in [\"SFCC\", \"SFCF\"]:\n",
    "            self.channel_fusion = crosschannel_aggregation[cross_channel_aggregation_type](input_shape[3],           2*filter_num)\n",
    "        else:\n",
    "            # 这里需要沿着时间轴走\n",
    "            self.channel_fusion = crosschannel_aggregation[cross_channel_aggregation_type](input_shape[3],           2*filter_num)\n",
    "            # --> B F L\n",
    "            # 需要reshape++++++++++++++++++++++++++++++\n",
    "\n",
    "            \n",
    "        # BLF\n",
    "        self.activation = nn.ReLU() \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        PART4  , ============= Temporal information Extraction =========================\n",
    "        这里可供选择的  gru lstm attn transformer   identity\n",
    "\n",
    "        输出格式为  Batch, downsampling_length, filter_num\n",
    "        \"\"\"\n",
    "        \n",
    "        # ++++++++++++ 这里需要讨论\n",
    "        self.temporal_interaction = temporal_interaction[temporal_info_interaction_type](input_shape[3],           2*filter_num)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 5 , =================== Temporal information Aggregation ================\n",
    "\n",
    "\n",
    "        输出格式为  Batch, downsampling_length, filter_num\n",
    "        \"\"\"        \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if temporal_info_aggregation_type == \"FC\":\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.temporal_fusion = temmporal_aggregation[temporal_info_aggregation_type](downsampling_length*2*filter_num,2*filter_num)\n",
    "        else:\n",
    "            self.temporal_fusion = temmporal_aggregation[temporal_info_aggregation_type](input_shape[3],           2*filter_num)\n",
    "            \n",
    "        #--> B F\n",
    "\n",
    "        # PART 6 , ==================== Prediction ==============================\n",
    "        self.prediction = nn.Linear(2*filter_num ,number_class)\n",
    "\n",
    "    def get_the_shape(self, input_shape):\n",
    "        x = torch.rand(input_shape)\n",
    "\n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)    \n",
    "\n",
    "        return x.shape[2]\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B F L C   \n",
    "        for layer in self.layers_conv:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.permute(0,3,2,1) \n",
    "        # ------->  B x C x L* x F*       \n",
    "\n",
    "\n",
    "\n",
    "        \"\"\" =============== cross channel interaction ===============\"\"\"\n",
    "        x = torch.cat(\n",
    "            [self.channel_interaction(x[:, :, t, :]).unsqueeze(3) for t in range(x.shape[2])],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # ------->  B x C x F* x L* \n",
    "        \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        \"\"\"=============== cross channel fusion ===============\"\"\"\n",
    "        \n",
    "        if self.cross_channel_aggregation_type == \"FC\":\n",
    "\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            x = x.reshape(x.shape[0], x.shape[1], -1)\n",
    "            x = self.activation(self.channel_fusion(x))\n",
    "        elif self.cross_channel_aggregation_type in [\"SFCC\",\"SFCF\",\"SFCF2\"]:\n",
    "            x = x.permute(0,3,1,2)\n",
    "            x = self.activation(self.channel_fusion(x)) \n",
    "        else:\n",
    "            x = torch.cat(\n",
    "                [self.channel_fusion(x[:, :, :, t]).unsqueeze(2) for t in range(x.shape[3])],\n",
    "                dim=-1,\n",
    "            )\n",
    "            x = x.permute(0,2,1)\n",
    "            x = self.activation(x)\n",
    "        # ------->  B x L* x F*\n",
    "            \n",
    "            \n",
    "        \"\"\"cross temporal interaction \"\"\"\n",
    "        x = self.temporal_interaction(x)\n",
    "\n",
    "\n",
    "        \n",
    "        \"\"\"cross temporal fusion \"\"\"\n",
    "        if self.temporal_info_aggregation_type == \"FC\":\n",
    "            x = self.flatten(x)\n",
    "            x = self.activation(self.temporal_fusion(x)) # B L C\n",
    "        else:\n",
    "            x = self.temporal_fusion(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        y = self.prediction(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db42d434-71d6-4865-9360-a9971ef4c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 150\n",
    "c_in = 18\n",
    "num_classes = 4\n",
    "filter_num = 12\n",
    "f_in = 1\n",
    "model  = TinyHAR_Model((1,f_in, input_length, c_in ), \n",
    "                       num_classes,\n",
    "                       filter_num = filter_num,\n",
    "                       cross_channel_interaction_type = \"attn\", \n",
    "                       cross_channel_aggregation_type = \"FC\",  \n",
    "                       temporal_info_interaction_type = \"lstm\",   \n",
    "                       temporal_info_aggregation_type = \"tnaive\"\n",
    "                      )    # naive  filter  FC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b8f3943-3b45-4726-a403-16a8958d26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight_path = \"/pfs/data5/home/kit/tm/px6680/Conference/ISWC2023/Run_logs/logs/model_tinyhar_data_jubot_seed_4_differencing_False_Seperation_False_magnitude_False_Mixup_0.5_RandomAug_0.5_Scaling_1.0_Mixupargmax_True_randomconfig_random_aug_all.yaml/cv_0/final_best_vali.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8264b8a-3a46-482e-9180-3fb1916343b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight= torch.load(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f13c4e-5c7e-49f4-a51a-a2313c3d5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_weights = {k.replace('model.', ''): v for k, v in weight.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68223f5c-4b45-47cc-98ea-86de0b1dbf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(modified_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664bfcf-864a-4cf0-bc5c-73207c22c222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc23",
   "language": "python",
   "name": "iswc23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
