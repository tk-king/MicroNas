{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99158b9-9309-4fb1-964b-cd803f9960f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joezh\\anaconda3\\envs\\wefa_dash\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ptflops import get_model_complexity_info\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "from CrossAttn import CrossAttn\n",
    "from deepSense import DeepSense\n",
    "from GlobalFusion import GlobalFusion\n",
    "from ALAE import ALAE_TAE\n",
    "from Attend import AttendDiscriminate\n",
    "from deepconvlstm import DeepConvLSTM\n",
    "from ifconv import If_ConvTransformer_W\n",
    "from TinyHAR import TinyHAR_Model\n",
    "from MixerMLP import FFTMIXER_HAR_Model\n",
    "from mcnn import MCNN\n",
    "from deepconvlstm_attn import DeepConvLSTM_ATTN\n",
    "from visionmixer import Vision_MIXER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd9e6e7-f1e8-427c-81c6-670ff8da0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [\n",
    "    {\"dataset_name\":\"pamap2\",  \"sensor_channel\":18, \"window_length\":128, #\n",
    "     \"fft_window_length\":8, \"nb_classes\":18, \"fft_feature_dim\":32, #\n",
    "     \"S_number_sensors_type\":2,\"L_sensor_locations\":3},#\n",
    "    \n",
    "    {\"dataset_name\":\"dsads\",  \"sensor_channel\":45, \"window_length\":125, #\n",
    "     \"fft_window_length\":5, \"nb_classes\":19, \"fft_feature_dim\":50, #\n",
    "     \"S_number_sensors_type\":3,\"L_sensor_locations\":5},#\n",
    "    \n",
    "    {\"dataset_name\":\"dg\",  \"sensor_channel\":9, \"window_length\":64, #\n",
    "     \"fft_window_length\":4, \"nb_classes\":2, \"fft_feature_dim\":32, #\n",
    "     \"S_number_sensors_type\":1,\"L_sensor_locations\":3},#\n",
    "\n",
    "    {\"dataset_name\":\"hapt\",  \"sensor_channel\":6, \"window_length\":128, #\n",
    "     \"fft_window_length\":8, \"nb_classes\":12, \"fft_feature_dim\":32, #\n",
    "     \"S_number_sensors_type\":2,\"L_sensor_locations\":1},#\n",
    "    \n",
    "    {\"dataset_name\":\"motionsense\",  \"sensor_channel\":12, \"window_length\":128, #\n",
    "     \"fft_window_length\":8, \"nb_classes\":6, \"fft_feature_dim\":32, \n",
    "     \"S_number_sensors_type\":4,\"L_sensor_locations\":1},#\n",
    "\n",
    "    {\"dataset_name\":\"mhealth\",  \"sensor_channel\":18, \"window_length\":128, #\n",
    "     \"fft_window_length\":8 , \"nb_classes\":12, \"fft_feature_dim\":32, #\n",
    "     \"S_number_sensors_type\":3,\"L_sensor_locations\":2}#\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a36bd95-35ad-4d9a-94de-3853be9026af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for data in data_dict:\n",
    "    #print(data)\n",
    "    result_data = {}\n",
    "    dataset_name=data[\"dataset_name\"]\n",
    "    sensor_channel=data[\"sensor_channel\"]\n",
    "    window_length=data[\"window_length\"]\n",
    "    fft_window_length=data[\"fft_window_length\"]\n",
    "    nb_classes=data[\"nb_classes\"]\n",
    "    fft_feature_dim=data[\"fft_feature_dim\"]\n",
    "    S_number_sensors_type=data[\"S_number_sensors_type\"]\n",
    "    L_sensor_locations=data[\"L_sensor_locations\"]\n",
    "    \n",
    "\n",
    "\n",
    "    # -------------------- Build Visionmixer ----------------\n",
    "\n",
    "\n",
    "    model  = Vision_MIXER(\n",
    "                input_shape=(1,1, window_length, sensor_channel ), \n",
    "                patch_size = 3,\n",
    "                number_class= nb_classes) \n",
    "    \n",
    "    macs, params = get_model_complexity_info(\n",
    "        model, \n",
    "        (1, window_length, sensor_channel), \n",
    "        as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    result_data[\"Vision_MIXER_macs\"] = macs\n",
    "    result_data[\"Vision_MIXER_params\"] = params\n",
    "\n",
    "    results[dataset_name] = result_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39adcec4-159e-4a05-99ed-475039aed3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pamap2': {'Vision_MIXER_macs': '214.16 MMac',\n",
       "  'Vision_MIXER_params': '836.96 k'},\n",
       " 'dsads': {'Vision_MIXER_macs': '522.72 MMac',\n",
       "  'Vision_MIXER_params': '1.08 M'},\n",
       " 'dg': {'Vision_MIXER_macs': '54.91 MMac', 'Vision_MIXER_params': '709.0 k'},\n",
       " 'hapt': {'Vision_MIXER_macs': '71.5 MMac', 'Vision_MIXER_params': '724.47 k'},\n",
       " 'motionsense': {'Vision_MIXER_macs': '142.83 MMac',\n",
       "  'Vision_MIXER_params': '778.4 k'},\n",
       " 'mhealth': {'Vision_MIXER_macs': '214.16 MMac',\n",
       "  'Vision_MIXER_params': '835.41 k'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdea60-409a-4949-b24e-a67b77fe9255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920692e-1d1c-448d-8404-3038ed85b411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfa157-6db9-48a5-bdd4-940ad36d1961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d397a7-e6d6-4d66-b2f5-2b01d1ed8a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea1850-fbb6-4382-ab27-6f325ec44f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ada3c-27e8-4943-8881-e058fc0944af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b03648-590a-4a5a-8900-cbe2abaf3e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b329f840-7290-4ea4-8e57-2a0fbf984381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e95a24-0142-4844-96ae-bdcedb7e84b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07721a9-7bba-4d7a-9135-2ff059059b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1a833-88df-4f2d-934b-164974595ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9320c-c89f-4cdc-badd-1da31995a29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a2d39-8e4d-49c0-8efd-7ec5c333dfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233695ee-d97e-490a-beac-7b863117ed3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e28ea-7dbb-49e8-b262-c7190fc69ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f89216-d369-4e4e-8897-add3db5a82ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c1320-ddc9-4e4e-aa6e-e02d6b378f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82769a5-72ae-458c-ac5f-43fdf597d966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915c3dd-b767-4892-9708-539909d8261b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df8a3d-ab64-45bb-bccc-4b668dd455b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b595e-897e-4024-afeb-8e9c4baa310b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998cce2-f8b8-4fcf-8e6a-4647dba78154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fce0b6-c3a0-4f6c-b19d-c34be06ee78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ea9a0-24a9-474e-916a-20f50e5fe3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5674c-4874-47fb-b071-2950ecd151a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264732aa-a7b0-41c1-a39e-61b4f2828fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598abd2-7642-467e-a9de-9cc3c5a07ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f3fec-c113-43b1-8841-4c2e51aacf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821285b-4984-4e80-9026-7c0603751f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd4bfc-dc47-4987-9b1a-12ac91bef514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d1613-613c-45ed-9d51-dfa727d616dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c162d-24a0-4631-8578-00f44d596696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e419bd-ecea-4435-98e4-ca29df558682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54080cab-d1f3-48a9-b338-af872bcc0a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c8097-a4db-4fcd-ba31-51727fe10ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86693b-076a-46a0-af17-47d8c654010d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3965c-52c1-4aa8-810e-f0e5a12c6abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b614f-0142-42c0-a75b-605425985e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773b86d-134d-4ec8-8f53-7508e9be043f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481be933-5e81-4e53-8534-ca2f35c99af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc64aa6-3894-408a-8ef2-c9722293bb46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c84a3d-0788-4724-8769-fc006f9bf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [\n",
    "    {\"dataset_name\":\"pamap2\",  \"sensor_channel\":18, \"window_length\":128, #\n",
    "     \"fft_window_length\":8, \"nb_classes\":18, \"fft_feature_dim\":32, #\n",
    "     \"S_number_sensors_type\":2,\"L_sensor_locations\":3},#\n",
    "    # {\"dataset_name\":\"dsads\",  \"sensor_channel\":30, \"window_length\":125, #\n",
    "    #  \"fft_window_length\":5, \"nb_classes\":19, \"fft_feature_dim\":50, #\n",
    "    #  \"S_number_sensors_type\":2,\"L_sensor_locations\":5},#\n",
    "    # {\"dataset_name\":\"dg\",  \"sensor_channel\":9, \"window_length\":64, #\n",
    "    #  \"fft_window_length\":4, \"nb_classes\":2, \"fft_feature_dim\":32, #\n",
    "    #  \"S_number_sensors_type\":1,\"L_sensor_locations\":3},#\n",
    "    # # {\"dataset_name\":\"rw\",  \"sensor_channel\":45, \"window_length\":100, #\n",
    "    # #  \"fft_window_length\":10, \"nb_classes\":8, \"fft_feature_dim\":20, #\n",
    "    # #  \"S_number_sensors_type\":3,\"L_sensor_locations\":5},#\n",
    "    # {\"dataset_name\":\"hapt\",  \"sensor_channel\":9, \"window_length\":128, #\n",
    "    #  \"fft_window_length\":8, \"nb_classes\":12, \"fft_feature_dim\":32, #\n",
    "    #  \"S_number_sensors_type\":3,\"L_sensor_locations\":1},#\n",
    "    # {\"dataset_name\":\"motionsense\",  \"sensor_channel\":12, \"window_length\":128, #\n",
    "    #  \"fft_window_length\":8, \"nb_classes\":6, \"fft_feature_dim\":32, \n",
    "    #  \"S_number_sensors_type\":4,\"L_sensor_locations\":1},#\n",
    "    # {\"dataset_name\":\"skoda\",  \"sensor_channel\":30, \"window_length\":128, #\n",
    "    #  \"fft_window_length\":8, \"nb_classes\":10, \"fft_feature_dim\":32, #\n",
    "    #  \"S_number_sensors_type\":1,\"L_sensor_locations\":10},#\n",
    "    # {\"dataset_name\":\"GesHome\",  \"sensor_channel\":9, \"window_length\":50,# \n",
    "    #  \"fft_window_length\":7, \"nb_classes\":18, \"fft_feature_dim\":20, #\n",
    "    #  \"S_number_sensors_type\":3,\"L_sensor_locations\":1},#\n",
    "    # {\"dataset_name\":\"lsign\",  \"sensor_channel\":15, \"window_length\":75, #\n",
    "    #  \"fft_window_length\":6, \"nb_classes\":36, \"fft_feature_dim\":40, #\n",
    "    #  \"S_number_sensors_type\":1,\"L_sensor_locations\":5},#\n",
    "    # {\"dataset_name\":\"emgg\",  \"sensor_channel\":9, \"window_length\":200, #\n",
    "    #  \"fft_window_length\":10, \"nb_classes\":7, \"fft_feature_dim\":40, #\n",
    "    #  \"S_number_sensors_type\":1,\"L_sensor_locations\":3},#\n",
    "    # {\"dataset_name\":\"hhar\",  \"sensor_channel\":6, \"window_length\":200, #\n",
    "    #  \"fft_window_length\":10, \"nb_classes\":6, \"fft_feature_dim\":40, #\n",
    "    #  \"S_number_sensors_type\":2,\"L_sensor_locations\":1},#\n",
    "    # {\"dataset_name\":\"mhealth\",  \"sensor_channel\":18, \"window_length\":128, #\n",
    "    #  \"fft_window_length\":8 , \"nb_classes\":12, \"fft_feature_dim\":32, #\n",
    "    #  \"S_number_sensors_type\":3,\"L_sensor_locations\":2}#\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4447b34b-7523-4c8e-ba34-4ce6427603db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module GlobalFusion is treated as a zero-op.\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for data in data_dict:\n",
    "    #print(data)\n",
    "    result_data = {}\n",
    "    dataset_name=data[\"dataset_name\"]\n",
    "    sensor_channel=data[\"sensor_channel\"]\n",
    "    window_length=data[\"window_length\"]\n",
    "    fft_window_length=data[\"fft_window_length\"]\n",
    "    nb_classes=data[\"nb_classes\"]\n",
    "    fft_feature_dim=data[\"fft_feature_dim\"]\n",
    "    S_number_sensors_type=data[\"S_number_sensors_type\"]\n",
    "    L_sensor_locations=data[\"L_sensor_locations\"]\n",
    "    \n",
    "    #  ----------------  build MCNN model ---------------------\n",
    "\n",
    "\n",
    "    config = { \"nb_conv_blocks\": 2,\n",
    "              \"nb_filters\": 64,\n",
    "              \"dilation\": 1,\n",
    "              \"batch_norm\": 0,\n",
    "              \"filter_width\": 5,\n",
    "              \"drop_prob\": 0.25}\n",
    "    model  = MCNN((1,1, window_length, sensor_channel ), \n",
    "                   nb_classes,\n",
    "                  1,\n",
    "                  config)\n",
    "\n",
    "\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    result_data[\"mcnn_macs\"] = macs\n",
    "    result_data[\"mcnn_params\"] = params\n",
    "    \n",
    "    #  ----------------  build DCL model ---------------------\n",
    "\n",
    "    config = {  \n",
    "        \"nb_conv_blocks\": 2,\n",
    "      \"nb_filters\": 64,\n",
    "      \"dilation\": 1,\n",
    "      \"batch_norm\": 0,\n",
    "      \"filter_width\": 11,\n",
    "      \"nb_layers_lstm\": 1,\n",
    "      \"drop_prob\": 0.2,\n",
    "      \"nb_units_lstm\": 128}\n",
    "    input_shape = (1, 1,window_length,sensor_channel)\n",
    "    model = DeepConvLSTM(input_shape, nb_classes, 1,config=config)\n",
    "    #x = torch.rand(1, 1, window_length, sensor_channel)\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    result_data[\"dcl_macs\"] = macs\n",
    "    result_data[\"dcl_params\"] = params\n",
    "\n",
    "    # -----------------build DeepConvLSTM Attend -------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    config = {  \n",
    "        \"nb_conv_blocks\": 2,\n",
    "        \"nb_filters\": 64,\n",
    "        \"dilation\": 1,\n",
    "        \"batch_norm\": 0,\n",
    "        \"filter_width\": 5,\n",
    "        \"nb_layers_lstm\": 2,\n",
    "        \"drop_prob\": 0.5,\n",
    "        \"nb_units_lstm\": 128}\n",
    "    model  = DeepConvLSTM_ATTN((1,1, window_length, sensor_channel ), \n",
    "                               nb_classes,\n",
    "                               1,\n",
    "                               config)\n",
    "\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    result_data[\"dcl_attn_macs\"] = macs\n",
    "    result_data[\"dcl_attn_params\"] = params\n",
    "    # -------------- build DeepSense Model \n",
    "\n",
    "    if fft_feature_dim<=21:\n",
    "        kernel_size = 3\n",
    "    else:\n",
    "        kernel_size = 5\n",
    "    model = DeepSense(input_shape=(1, 1, window_length, sensor_channel),   fft_segments_length = int(fft_feature_dim/2),   \n",
    "                      k_number_sensors_group=S_number_sensors_type*L_sensor_locations, nb_classes= nb_classes, kernel_size_1=kernel_size)\n",
    "\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "    result_data[\"DeepSense_macs\"] = macs\n",
    "    result_data[\"DeepSense_params\"] = params\n",
    "\n",
    "    # ==============build  Globalfusion model \n",
    "\n",
    "    model = GlobalFusion(input_shape=(1, 1, window_length, sensor_channel),      fft_segments_length = int(fft_feature_dim/2),   \n",
    "                         S_number_sensors_type=S_number_sensors_type, \n",
    "                         L_sensor_locations= L_sensor_locations, nb_classes= nb_classes, kernel_size_1 = kernel_size)\n",
    "\n",
    "\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=True)\n",
    "\n",
    "    result_data[\"GlobalFusion_macs\"] = macs\n",
    "    result_data[\"GlobalFusion_params\"] = params\n",
    "\n",
    "    # ---------------- Build Attend\n",
    "    input_shape = (1, 1,window_length,sensor_channel)\n",
    "    config = {\"hidden_dim\": 128,\n",
    "      \"filter_num\": 64,\n",
    "      \"filter_size\": 5,\n",
    "      \"enc_num_layers\": 2,\n",
    "      \"dropout\": 0.5,\n",
    "      \"dropout_rnn\": 0.25,\n",
    "      \"dropout_cls\": 0.5,\n",
    "      \"activation\": \"ReLU\",\n",
    "      \"sa_div\": 1}\n",
    "    model = AttendDiscriminate(input_shape, nb_classes, config=config)\n",
    "    #x = torch.rand(1, 1, window_length, sensor_channel)\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    result_data[\"Attend_macs\"] = macs\n",
    "    result_data[\"Attend_params\"] = params\n",
    "    # ---------- Build ALAE ----------\n",
    "\n",
    "\n",
    "    model = ALAE_TAE(input_shape=(1, 1, window_length, sensor_channel),      \n",
    "                     nb_classes=nb_classes)\n",
    "\n",
    "    #x = torch.rand(1, 1, window_length, sensor_channel)\n",
    "    macs, params = get_model_complexity_info(model, \n",
    "                                             (1, window_length, sensor_channel), \n",
    "                                             as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    result_data[\"ALAE_macs\"] = macs\n",
    "    result_data[\"ALAE_params\"] = params\n",
    "\n",
    "    \n",
    "    # ---------Build  IF Conv --------------\n",
    "\n",
    "\n",
    "    \n",
    "    if sensor_channel%9==0:\n",
    "        \n",
    "        fusion = True\n",
    "    else:\n",
    "        fusion = False\n",
    "    model = If_ConvTransformer_W(1, sensor_channel, 32, 5, 3, 2, 64, 1, 0.2, dataset_name, window_length, nb_classes, fusion = fusion)\n",
    "    \n",
    "    #input = torch.randn(1, 1,sensor_channel , window_length)\n",
    "\n",
    "    \n",
    "    \n",
    "    macs, params = get_model_complexity_info(model, (1,sensor_channel , window_length), as_strings=True,\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    result_data[\"IfConv_macs\"] = macs\n",
    "    result_data[\"IfConv_params\"] = params\n",
    "\n",
    "\n",
    "    # -------------------- Build TinyHAR ----------------\n",
    "\n",
    "    filter_num = 32\n",
    "    model  = TinyHAR_Model((1,1, window_length, sensor_channel ), \n",
    "                           nb_classes,\n",
    "                           filter_num = filter_num,#config[\"filter_num\"],\n",
    "                           cross_channel_interaction_type = \"attn\",    # attn  transformer  identity\n",
    "                           cross_channel_aggregation_type = \"FC\",  # filter  naive  FC\n",
    "                           temporal_info_interaction_type = \"lstm\",     # gru  lstm  attn  transformer  identity\n",
    "                           temporal_info_aggregation_type = \"tnaive\")    # naive  filter  FC )\n",
    "    \n",
    "    macs, params = get_model_complexity_info(\n",
    "        model, \n",
    "        (1, window_length, sensor_channel), \n",
    "        as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    result_data[\"tinyhar_macs\"] = macs\n",
    "    result_data[\"tinyhar_params\"] = params\n",
    "\n",
    "    results[dataset_name] = result_data\n",
    "    # --------------- Build cross Attention -------------\n",
    "\n",
    "\n",
    "    # model = CrossAttn(\n",
    "    #     Ts_input_shape = (1,1,window_length,sensor_channel),\n",
    "    #     hidden_dim   = 24,\n",
    "    #     FFT_input_shape = (1,fft_feature_dim,fft_window_length,sensor_channel)\n",
    "    # )\n",
    "\n",
    "\n",
    "    # def prepare_input(resolution):\n",
    "    #     x1 = torch.FloatTensor(1, 1, window_length, sensor_channel)\n",
    "    #     x2 = torch.FloatTensor(1, fft_feature_dim, fft_window_length, sensor_channel)\n",
    "    #     return dict(x = [x1, x2])\n",
    "\n",
    "\n",
    "\n",
    "    # macs, params = get_model_complexity_info(model, \n",
    "    #                                          (1, window_length, sensor_channel), \n",
    "    #                                          input_constructor=prepare_input, \n",
    "    #                                          as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "    # result_data[\"CrossAttn_macs\"] = macs\n",
    "    # result_data[\"CrossAttn_params\"] = params\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # results[dataset_name] = result_data\n",
    "\n",
    "    # ----------------- build the Mixer Model -------------\n",
    "\n",
    "    # config[\"fft_mixer_share_flag\"] = False\n",
    "    # config[\"fft_mixer_temporal_flag\"]  = True\n",
    "    # config[\"fft_mixer_FFT_flag\"]  = True\n",
    "    # model  = FFTMIXER_HAR_Model(input_shape=(1,1, window_length, sensor_channel ), \n",
    "    #                             number_class = nb_classes,\n",
    "    #                             filter_num = 6,\n",
    "    #                             fft_mixer_segments_length = int(fft_feature_dim/2),\n",
    "    #                             expansion_factor = 0.3,\n",
    "    #                             fft_mixer_layer_nr = 2,\n",
    "    #                             fuse_early = False,\n",
    "    #                             temporal_merge= True,\n",
    "    #                             oration = 0.25,\n",
    "    #                             model_config = config)\n",
    "    \n",
    "    # macs, params = get_model_complexity_info(model, (1,window_length , sensor_channel), as_strings=True,\n",
    "    #                                        print_per_layer_stat=False, verbose=False)\n",
    "\n",
    "\n",
    "    # result_data[\"Mixer_macs\"] = macs\n",
    "    # result_data[\"Mixer_params\"] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5a0bbe-7658-4a81-a694-f35e1f428860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pamap2': {'mcnn_macs': '58.25 MMac',\n",
       "  'mcnn_params': '638.03 k',\n",
       "  'dcl_macs': '299.23 MMac',\n",
       "  'dcl_params': '794.83 k',\n",
       "  'dcl_attn_macs': '221.08 MMac',\n",
       "  'dcl_attn_params': '869.46 k',\n",
       "  'DeepSense_macs': '87.88 MMac',\n",
       "  'DeepSense_params': '886.8 k',\n",
       "  'GlobalFusion_macs': '105.79 MMac',\n",
       "  'GlobalFusion_params': '394.07 k',\n",
       "  'Attend_macs': '226.54 MMac',\n",
       "  'Attend_params': '668.12 k',\n",
       "  'ALAE_macs': '190.41 MMac',\n",
       "  'ALAE_params': '413.52 k',\n",
       "  'IfConv_macs': '87.4 MMac',\n",
       "  'IfConv_params': '171.13 k',\n",
       "  'tinyhar_macs': '12.95 MMac',\n",
       "  'tinyhar_params': '90.48 k'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0547c1-4f85-49bd-af8b-9007e2c26f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = {}\n",
    "for key1 in results.keys():\n",
    "    temp = results[key1]\n",
    "    df_re[\"{}_macs\".format(key1)] = []\n",
    "    df_re[\"{}_params\".format(key1)] = []\n",
    "    for key2 in temp.keys():\n",
    "        if \"macs\" in key2:\n",
    "            value = float(temp[key2].split(\" \")[0])\n",
    "            scale = temp[key2].split(\" \")[1]\n",
    "            if \"KM\" in scale:\n",
    "                value = value *1000\n",
    "            elif \"MM\" in scale:\n",
    "                value = value *1000000\n",
    "            elif \"GM\" in scale:\n",
    "                value = value *1000000000\n",
    "            else:\n",
    "                assert 1==0\n",
    "                \n",
    "            df_re[\"{}_macs\".format(key1)].append(value/1000000)\n",
    "        if \"params\" in key2:\n",
    "            value = float(temp[key2].split(\" \")[0])\n",
    "            scale = temp[key2].split(\" \")[1]\n",
    "            if \"k\" in scale:\n",
    "                value = value *1000\n",
    "            elif \"M\" in scale:\n",
    "                value = value *1000000\n",
    "            elif \"G\" in scale:\n",
    "                value = value *1000000000\n",
    "            else:\n",
    "                assert 1==0\n",
    "\n",
    "            \n",
    "            df_re[\"{}_params\".format(key1)].append(value/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e1055-8dea-4568-8669-efc124c5e82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66d47e0-725e-4e09-a9ec-fe0ffa2e9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(df_re).T.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf7fd9-48fe-47b0-8a16-d05336af45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3873639-873a-499f-ad8c-c64e5acb0629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599558c-ff76-4b55-a24b-0b7b3d653ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19d316-c84b-415f-be31-252cdffb337a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
